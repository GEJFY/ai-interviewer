# AIé¢æ¥ã‚·ã‚¹ãƒ†ãƒ  é‹ç”¨ãƒãƒ‹ãƒ¥ã‚¢ãƒ«

**ãƒãƒ¼ã‚¸ãƒ§ãƒ³:** 1.0
**æœ€çµ‚æ›´æ–°æ—¥:** 2026-02-15
**å¯¾è±¡è€…:** ã‚·ã‚¹ãƒ†ãƒ é‹ç”¨æ‹…å½“è€…ã€SREãƒãƒ¼ãƒ 

---

## ç›®æ¬¡

1. [ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ](#1-ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ)
2. [æ—¥å¸¸é‹ç”¨](#2-æ—¥å¸¸é‹ç”¨)
3. [ç›£è¦–è¨­å®š](#3-ç›£è¦–è¨­å®š)
4. [ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œ](#4-ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œ)
5. [ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°](#5-ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°)
6. [ãƒ‡ãƒ—ãƒ­ã‚¤é‹ç”¨](#6-ãƒ‡ãƒ—ãƒ­ã‚¤é‹ç”¨)
7. [ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é‹ç”¨](#7-ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é‹ç”¨)

---

## 1. ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ

### 1.1 ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ãƒ¦ãƒ¼ã‚¶ãƒ¼                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ HTTPS (443)
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼                           â”‚
â”‚                    (ALB / Cloud LB)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                              â”‚
             â”‚ Port 3001                    â”‚ Port 8001
             â–¼                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Webãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰   â”‚          â”‚      APIãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰      â”‚
â”‚   Next.js 15        â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚      FastAPI           â”‚
â”‚   React 19          â”‚ WebSocketâ”‚      Python 3.11+      â”‚
â”‚   pnpm + turbo      â”‚          â”‚      /api/v1/*         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚                    â”‚                    â”‚
                        â–¼                    â–¼                    â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   PostgreSQL 15+  â”‚  â”‚   Redis 7+   â”‚  â”‚   AI Provider    â”‚
              â”‚   Port 5432      â”‚  â”‚   Port 6379  â”‚  â”‚ Azure OpenAI /   â”‚
              â”‚   asyncpg        â”‚  â”‚   Cache      â”‚  â”‚ AWS Bedrock /    â”‚
              â”‚                  â”‚  â”‚              â”‚  â”‚ GCP Vertex AI    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆä¸€è¦§

| ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ | æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ | å½¹å‰² | å†—é•·æ§‹æˆ |
|-------------|------------|------|---------|
| **Webãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰** | Next.js 15, React 19 | ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ | æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒ«å¯ (2å°ä»¥ä¸Šæ¨å¥¨) |
| **APIãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰** | FastAPI, Python 3.11+ | ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã€APIæä¾› | æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒ«å¯ (3å°ä»¥ä¸Šæ¨å¥¨) |
| **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹** | PostgreSQL 15+ | æ°¸ç¶šãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ | Primary-Replicaæ§‹æˆ |
| **ã‚­ãƒ£ãƒƒã‚·ãƒ¥** | Redis 7+ | ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ | Redis Cluster / Sentinel |
| **AI Provider** | Azure OpenAI / Bedrock / Vertex AI | AIé¢æ¥å‡¦ç† | ãƒãƒ«ãƒãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å¯¾å¿œ |
| **èªè¨¼** | JWT (access + refresh token) | ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼ã€MFAå¯¾å¿œ | ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹ |
| **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€šä¿¡** | WebSocket | é¢æ¥ã‚»ãƒƒã‚·ãƒ§ãƒ³ | æ°¸ç¶šæ¥ç¶šç®¡ç† |

### 1.3 ãƒãƒ¼ãƒˆä¸€è¦§

| ã‚µãƒ¼ãƒ“ã‚¹ | ãƒãƒ¼ãƒˆç•ªå· | ãƒ—ãƒ­ãƒˆã‚³ãƒ« | ç”¨é€” | ã‚¢ã‚¯ã‚»ã‚¹åˆ¶é™ |
|---------|-----------|----------|------|------------|
| API Backend | 8001 | HTTP/WS | REST APIã€WebSocket | å†…éƒ¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ |
| Web Frontend | 3001 | HTTP | Next.jsé–‹ç™ºã‚µãƒ¼ãƒãƒ¼ | å†…éƒ¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ |
| PostgreSQL | 5432 | TCP | ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š | DBå°‚ç”¨VLAN |
| Redis | 6379 | TCP | ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¥ç¶š | Cacheå°‚ç”¨VLAN |
| HTTPS (Production) | 443 | HTTPS | å¤–éƒ¨å…¬é–‹ | ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆ |

### 1.4 ç’°å¢ƒå¤‰æ•°ä¸€è¦§

#### ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ç’°å¢ƒå¤‰æ•° (.env)

```bash
# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åŸºæœ¬è¨­å®š
APP_NAME=AI Interview System
APP_VERSION=1.0.0
ENVIRONMENT=production  # development / staging / production
DEBUG=false
LOG_LEVEL=INFO  # DEBUG / INFO / WARNING / ERROR / CRITICAL

# APIè¨­å®š
API_HOST=0.0.0.0
API_PORT=8001
API_PREFIX=/api/v1
ALLOWED_ORIGINS=https://app.example.com,https://staging.example.com

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š
DATABASE_URL=postgresql+asyncpg://user:password@db-host:5432/ai_interviewer
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=10
DATABASE_POOL_TIMEOUT=30
DATABASE_ECHO=false

# Redisè¨­å®š
REDIS_URL=redis://redis-host:6379/0
REDIS_PASSWORD=your_redis_password
REDIS_MAX_CONNECTIONS=50
REDIS_SOCKET_TIMEOUT=5

# JWTèªè¨¼è¨­å®š
JWT_SECRET_KEY=your-super-secret-jwt-key-min-32-chars
JWT_ALGORITHM=HS256
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30
JWT_REFRESH_TOKEN_EXPIRE_DAYS=7

# MFAè¨­å®š
MFA_ENABLED=true
MFA_ISSUER=AI Interview System
TOTP_SECRET_KEY=your-totp-secret-key

# AI Providerè¨­å®š (Azure OpenAI)
AI_PROVIDER=azure_openai  # azure_openai / aws_bedrock / gcp_vertex
AZURE_OPENAI_API_KEY=your-azure-openai-api-key
AZURE_OPENAI_ENDPOINT=https://your-instance.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT=gpt-4
AZURE_OPENAI_API_VERSION=2024-02-15-preview
AZURE_OPENAI_MAX_RETRIES=3
AZURE_OPENAI_TIMEOUT=60

# AI Providerè¨­å®š (AWS Bedrock - ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
BEDROCK_MODEL_ID=anthropic.claude-v2

# AI Providerè¨­å®š (GCP Vertex AI - ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
GCP_PROJECT_ID=your-gcp-project
GCP_LOCATION=us-central1
VERTEX_AI_MODEL=gemini-pro

# WebSocketè¨­å®š
WS_HEARTBEAT_INTERVAL=30
WS_MAX_CONNECTIONS_PER_USER=3
WS_MESSAGE_MAX_SIZE=1048576  # 1MB

# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š
CORS_ALLOWED_ORIGINS=https://app.example.com
RATE_LIMIT_PER_MINUTE=60
SESSION_TIMEOUT_MINUTES=60
CSRF_SECRET_KEY=your-csrf-secret-key

# ç›£è¦–è¨­å®š
SENTRY_DSN=https://your-sentry-dsn@sentry.io/project-id
SENTRY_ENVIRONMENT=production
SENTRY_TRACES_SAMPLE_RATE=0.1

# é€šçŸ¥è¨­å®š
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL
TEAMS_WEBHOOK_URL=https://outlook.office.com/webhook/YOUR/WEBHOOK/URL
EMAIL_SMTP_HOST=smtp.gmail.com
EMAIL_SMTP_PORT=587
EMAIL_FROM_ADDRESS=noreply@example.com
```

#### ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç’°å¢ƒå¤‰æ•° (.env.local)

```bash
# Next.jsè¨­å®š
NEXT_PUBLIC_APP_NAME=AI Interview System
NEXT_PUBLIC_APP_VERSION=1.0.0
NEXT_PUBLIC_ENVIRONMENT=production

# APIæ¥ç¶šè¨­å®š
NEXT_PUBLIC_API_BASE_URL=https://api.example.com/api/v1
NEXT_PUBLIC_WS_BASE_URL=wss://api.example.com/api/v1/ws

# èªè¨¼è¨­å®š
NEXT_PUBLIC_AUTH_ENABLED=true
NEXT_PUBLIC_MFA_ENABLED=true

# æ©Ÿèƒ½ãƒ•ãƒ©ã‚°
NEXT_PUBLIC_FEATURE_CHAT_ENABLED=true
NEXT_PUBLIC_FEATURE_VIDEO_ENABLED=true
NEXT_PUBLIC_FEATURE_ANALYTICS_ENABLED=true

# ç›£è¦–è¨­å®š
NEXT_PUBLIC_SENTRY_DSN=https://your-sentry-dsn@sentry.io/project-id
NEXT_PUBLIC_GA_TRACKING_ID=G-XXXXXXXXXX
```

---

## 2. æ—¥å¸¸é‹ç”¨

### 2.1 ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯æ‰‹é †

#### 2.1.1 åŸºæœ¬ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯

APIã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å®šæœŸçš„ã«ç¢ºèªã—ã¾ã™ã€‚

**ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ:**
```
GET /api/v1/health
```

**æ­£å¸¸ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ä¾‹:**
```json
{
  "status": "healthy",
  "version": "1.0.0",
  "environment": "production",
  "timestamp": "2026-02-15T10:30:00Z",
  "checks": {
    "database": {
      "status": "healthy",
      "response_time_ms": 12,
      "connection_pool": {
        "size": 20,
        "in_use": 5,
        "available": 15
      }
    },
    "redis": {
      "status": "healthy",
      "response_time_ms": 3,
      "connected": true,
      "memory_used_mb": 128
    },
    "ai_provider": {
      "status": "healthy",
      "provider": "azure_openai",
      "response_time_ms": 450,
      "quota_remaining": 95000
    }
  }
}
```

**ç•°å¸¸æ™‚ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä¾‹:**
```json
{
  "status": "degraded",
  "version": "1.0.0",
  "environment": "production",
  "timestamp": "2026-02-15T10:30:00Z",
  "checks": {
    "database": {
      "status": "healthy",
      "response_time_ms": 15
    },
    "redis": {
      "status": "unhealthy",
      "error": "Connection timeout after 5000ms",
      "connected": false
    },
    "ai_provider": {
      "status": "healthy",
      "provider": "azure_openai",
      "response_time_ms": 520
    }
  }
}
```

#### 2.1.2 ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚³ãƒãƒ³ãƒ‰

**curlã§ã®ç¢ºèª:**
```bash
curl -X GET https://api.example.com/api/v1/health \
  -H "Accept: application/json" \
  -w "\nHTTP Status: %{http_code}\nTotal Time: %{time_total}s\n"
```

**ç›£è¦–ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹ (Bash):**
```bash
#!/bin/bash
# health_check.sh

HEALTH_URL="https://api.example.com/api/v1/health"
SLACK_WEBHOOK="your-slack-webhook-url"

response=$(curl -s -w "\n%{http_code}" "$HEALTH_URL")
http_code=$(echo "$response" | tail -n1)
body=$(echo "$response" | head -n-1)

if [ "$http_code" -ne 200 ]; then
  message="âš ï¸ Health Check Failed: HTTP $http_code\n$body"
  curl -X POST "$SLACK_WEBHOOK" \
    -H 'Content-Type: application/json' \
    -d "{\"text\":\"$message\"}"
  exit 1
fi

status=$(echo "$body" | jq -r '.status')
if [ "$status" != "healthy" ]; then
  message="âš ï¸ System Status: $status\n\`\`\`$body\`\`\`"
  curl -X POST "$SLACK_WEBHOOK" \
    -H 'Content-Type: application/json' \
    -d "{\"text\":\"$message\"}"
  exit 1
fi

echo "âœ… Health Check Passed"
exit 0
```

**crontabã§ã®å®šæœŸå®Ÿè¡Œè¨­å®š:**
```bash
# 5åˆ†ã”ã¨ã«ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
*/5 * * * * /opt/scripts/health_check.sh >> /var/log/health_check.log 2>&1
```

### 2.2 ãƒ­ã‚°ç¢ºèªæ–¹æ³•

#### 2.2.1 ãƒ­ã‚°å½¢å¼

æœ¬ã‚·ã‚¹ãƒ†ãƒ ã¯æ§‹é€ åŒ–ãƒ­ã‚° (JSONå½¢å¼) ã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™ã€‚

**ãƒ­ã‚°å‡ºåŠ›ä¾‹:**
```json
{
  "timestamp": "2026-02-15T10:30:00.123Z",
  "level": "INFO",
  "service": "api-backend",
  "module": "grc_backend.api.routes.interviews",
  "request_id": "req_abc123xyz",
  "user_id": "user_123",
  "message": "Interview session started",
  "context": {
    "interview_id": "interview_456",
    "session_id": "session_789",
    "duration_minutes": 30
  },
  "performance": {
    "response_time_ms": 245
  }
}
```

#### 2.2.2 ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«å®šç¾©

| ãƒ¬ãƒ™ãƒ« | ç”¨é€” | ä¿å­˜æœŸé–“ |
|-------|------|---------|
| **DEBUG** | é–‹ç™ºæ™‚ã®ãƒ‡ãƒãƒƒã‚°æƒ…å ± | 3æ—¥ |
| **INFO** | é€šå¸¸ã®å‹•ä½œãƒ­ã‚° (APIå‘¼ã³å‡ºã—ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ç­‰) | 30æ—¥ |
| **WARNING** | è­¦å‘Š (ãƒªãƒˆãƒ©ã‚¤æˆåŠŸã€è»½å¾®ãªã‚¨ãƒ©ãƒ¼) | 90æ—¥ |
| **ERROR** | ã‚¨ãƒ©ãƒ¼ (å‡¦ç†å¤±æ•—ã€ä¾‹å¤–ç™ºç”Ÿ) | 180æ—¥ |
| **CRITICAL** | é‡å¤§ãªã‚¨ãƒ©ãƒ¼ (ã‚·ã‚¹ãƒ†ãƒ åœæ­¢ãƒ¬ãƒ™ãƒ«) | 365æ—¥ |

#### 2.2.3 ãƒ­ã‚°ç¢ºèªã‚³ãƒãƒ³ãƒ‰

**Dockerã‚³ãƒ³ãƒ†ãƒŠã®ãƒ­ã‚°ç¢ºèª:**
```bash
# APIãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®ãƒ­ã‚° (æœ€æ–°100è¡Œ)
docker logs --tail 100 ai-interviewer-api

# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ãƒ­ã‚°ã‚’è¿½è·¡
docker logs -f ai-interviewer-api

# ç‰¹å®šæ™‚é–“ç¯„å›²ã®ãƒ­ã‚°
docker logs --since "2026-02-15T10:00:00" --until "2026-02-15T11:00:00" ai-interviewer-api
```

**JSONãƒ­ã‚°ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° (jqä½¿ç”¨):**
```bash
# ERRORãƒ¬ãƒ™ãƒ«ä»¥ä¸Šã®ãƒ­ã‚°ã®ã¿æŠ½å‡º
docker logs ai-interviewer-api | grep '^{' | jq 'select(.level == "ERROR" or .level == "CRITICAL")'

# ç‰¹å®šãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ­ã‚°ã‚’æŠ½å‡º
docker logs ai-interviewer-api | grep '^{' | jq 'select(.user_id == "user_123")'

# APIå¿œç­”æ™‚é–“ãŒ1ç§’ä»¥ä¸Šã®ãƒ­ã‚°ã‚’æŠ½å‡º
docker logs ai-interviewer-api | grep '^{' | jq 'select(.performance.response_time_ms > 1000)'

# éå»1æ™‚é–“ã®ã‚¨ãƒ©ãƒ¼æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
docker logs --since "1h" ai-interviewer-api | grep '^{' | jq -r '.level' | grep ERROR | wc -l
```

**Kubernetesç’°å¢ƒã§ã®ãƒ­ã‚°ç¢ºèª:**
```bash
# Podä¸€è¦§å–å¾—
kubectl get pods -n ai-interviewer

# ç‰¹å®šPodã®ãƒ­ã‚°ç¢ºèª
kubectl logs -n ai-interviewer ai-interviewer-api-7d9f8c5b6-abcde

# å…¨ã¦ã®APIãƒ¬ãƒ—ãƒªã‚«ã®ãƒ­ã‚°ã‚’ç¢ºèª
kubectl logs -n ai-interviewer -l app=ai-interviewer-api --tail=50

# ãƒ­ã‚°ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
kubectl logs -n ai-interviewer ai-interviewer-api-7d9f8c5b6-abcde > /tmp/api-logs.json
```

### 2.3 ãƒãƒƒãƒå‡¦ç†

#### 2.3.1 å®šæœŸãƒãƒƒãƒä¸€è¦§

| ãƒãƒƒãƒå | å®Ÿè¡Œé »åº¦ | å®Ÿè¡Œæ™‚é–“ | ç›®çš„ |
|---------|---------|---------|------|
| **expired_sessions_cleanup** | æ¯æ™‚ | æ¯æ™‚00åˆ† | æœŸé™åˆ‡ã‚Œã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å‰Šé™¤ |
| **token_cleanup** | æ¯æ—¥ | 02:00 | æœŸé™åˆ‡ã‚Œãƒˆãƒ¼ã‚¯ãƒ³ã®å‰Šé™¤ |
| **analytics_aggregation** | æ¯æ—¥ | 03:00 | åˆ†æãƒ‡ãƒ¼ã‚¿ã®é›†è¨ˆ |
| **backup_verification** | æ¯æ—¥ | 04:00 | ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®æ¤œè¨¼ |
| **log_rotation** | æ¯æ—¥ | 05:00 | ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ |
| **certificate_check** | æ¯é€±æœˆæ›œ | 06:00 | SSLè¨¼æ˜æ›¸ã®æœ‰åŠ¹æœŸé™ãƒã‚§ãƒƒã‚¯ |
| **dependency_scan** | æ¯é€±æœˆæ›œ | 07:00 | ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®è„†å¼±æ€§ã‚¹ã‚­ãƒ£ãƒ³ |
| **monthly_report** | æ¯æœˆ1æ—¥ | 08:00 | æœˆæ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ |

#### 2.3.2 ãƒãƒƒãƒå®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰

**æ‰‹å‹•å®Ÿè¡Œä¾‹:**
```bash
# æœŸé™åˆ‡ã‚Œã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
python -m grc_backend.batch.cleanup_sessions

# ãƒˆãƒ¼ã‚¯ãƒ³ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
python -m grc_backend.batch.cleanup_tokens

# åˆ†æãƒ‡ãƒ¼ã‚¿é›†è¨ˆ
python -m grc_backend.batch.aggregate_analytics --date 2026-02-15

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¤œè¨¼
python -m grc_backend.batch.verify_backups --backup-path /backups/latest
```

**crontabè¨­å®šä¾‹:**
```bash
# æ¯æ™‚00åˆ†: æœŸé™åˆ‡ã‚Œã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
0 * * * * cd /app && python -m grc_backend.batch.cleanup_sessions >> /var/log/batch/cleanup_sessions.log 2>&1

# æ¯æ—¥02:00: ãƒˆãƒ¼ã‚¯ãƒ³ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
0 2 * * * cd /app && python -m grc_backend.batch.cleanup_tokens >> /var/log/batch/cleanup_tokens.log 2>&1

# æ¯æ—¥03:00: åˆ†æãƒ‡ãƒ¼ã‚¿é›†è¨ˆ
0 3 * * * cd /app && python -m grc_backend.batch.aggregate_analytics >> /var/log/batch/analytics.log 2>&1

# æ¯é€±æœˆæ›œ06:00: è¨¼æ˜æ›¸ãƒã‚§ãƒƒã‚¯
0 6 * * 1 cd /app && python -m grc_backend.batch.check_certificates >> /var/log/batch/cert_check.log 2>&1
```

---

## 3. ç›£è¦–è¨­å®š

### 3.1 ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¸€è¦§

#### 3.1.1 ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ãƒ¡ãƒˆãƒªã‚¯ã‚¹

| ã‚«ãƒ†ã‚´ãƒª | ãƒ¡ãƒˆãƒªã‚¯ã‚¹å | èª¬æ˜ | åé›†é–“éš” | ä¿å­˜æœŸé–“ |
|---------|------------|------|---------|---------|
| **CPU** | `cpu_usage_percent` | CPUä½¿ç”¨ç‡ (%) | 15ç§’ | 30æ—¥ |
| **ãƒ¡ãƒ¢ãƒª** | `memory_usage_percent` | ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ (%) | 15ç§’ | 30æ—¥ |
| **ãƒ¡ãƒ¢ãƒª** | `memory_available_mb` | åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒª (MB) | 15ç§’ | 30æ—¥ |
| **ãƒ‡ã‚£ã‚¹ã‚¯** | `disk_usage_percent` | ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡ (%) | 1åˆ† | 90æ—¥ |
| **ãƒ‡ã‚£ã‚¹ã‚¯** | `disk_io_read_bytes` | ãƒ‡ã‚£ã‚¹ã‚¯I/Oèª­ã¿å–ã‚Š (bytes) | 15ç§’ | 7æ—¥ |
| **ãƒ‡ã‚£ã‚¹ã‚¯** | `disk_io_write_bytes` | ãƒ‡ã‚£ã‚¹ã‚¯I/Oæ›¸ãè¾¼ã¿ (bytes) | 15ç§’ | 7æ—¥ |
| **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯** | `network_in_bytes` | ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å—ä¿¡ (bytes) | 15ç§’ | 7æ—¥ |
| **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯** | `network_out_bytes` | ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é€ä¿¡ (bytes) | 15ç§’ | 7æ—¥ |

#### 3.1.2 ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¡ãƒˆãƒªã‚¯ã‚¹

| ã‚«ãƒ†ã‚´ãƒª | ãƒ¡ãƒˆãƒªã‚¯ã‚¹å | èª¬æ˜ | åé›†é–“éš” | ä¿å­˜æœŸé–“ |
|---------|------------|------|---------|---------|
| **API** | `api_request_count` | API ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•° | 15ç§’ | 90æ—¥ |
| **API** | `api_request_duration_ms` | APIå¿œç­”æ™‚é–“ (ms) - P50/P95/P99 | 15ç§’ | 90æ—¥ |
| **API** | `api_error_rate` | APIã‚¨ãƒ©ãƒ¼ç‡ (%) | 15ç§’ | 90æ—¥ |
| **API** | `api_requests_per_endpoint` | ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆåˆ¥ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•° | 1åˆ† | 30æ—¥ |
| **WebSocket** | `websocket_active_connections` | ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªWebSocketæ¥ç¶šæ•° | 15ç§’ | 7æ—¥ |
| **WebSocket** | `websocket_message_count` | WebSocketãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•° | 15ç§’ | 7æ—¥ |
| **WebSocket** | `websocket_disconnect_count` | WebSocketåˆ‡æ–­å›æ•° | 15ç§’ | 30æ—¥ |
| **èªè¨¼** | `auth_login_count` | ãƒ­ã‚°ã‚¤ãƒ³è©¦è¡Œå›æ•° | 1åˆ† | 90æ—¥ |
| **èªè¨¼** | `auth_login_success_rate` | ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸç‡ (%) | 1åˆ† | 90æ—¥ |
| **èªè¨¼** | `auth_mfa_verification_count` | MFAæ¤œè¨¼å›æ•° | 1åˆ† | 90æ—¥ |
| **é¢æ¥** | `interview_active_sessions` | ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªé¢æ¥ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•° | 15ç§’ | 30æ—¥ |
| **é¢æ¥** | `interview_completion_rate` | é¢æ¥å®Œäº†ç‡ (%) | 1æ™‚é–“ | 90æ—¥ |

#### 3.1.3 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹

| ã‚«ãƒ†ã‚´ãƒª | ãƒ¡ãƒˆãƒªã‚¯ã‚¹å | èª¬æ˜ | åé›†é–“éš” | ä¿å­˜æœŸé–“ |
|---------|------------|------|---------|---------|
| **æ¥ç¶š** | `db_connection_pool_size` | DBæ¥ç¶šãƒ—ãƒ¼ãƒ«ã‚µã‚¤ã‚º | 15ç§’ | 30æ—¥ |
| **æ¥ç¶š** | `db_connection_pool_in_use` | DBæ¥ç¶šãƒ—ãƒ¼ãƒ«ä½¿ç”¨ä¸­ | 15ç§’ | 30æ—¥ |
| **æ¥ç¶š** | `db_connection_pool_available` | DBæ¥ç¶šãƒ—ãƒ¼ãƒ«åˆ©ç”¨å¯èƒ½ | 15ç§’ | 30æ—¥ |
| **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹** | `db_query_duration_ms` | DBã‚¯ã‚¨ãƒªå®Ÿè¡Œæ™‚é–“ (ms) - P50/P95/P99 | 15ç§’ | 30æ—¥ |
| **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹** | `db_slow_query_count` | ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªæ•° (>1ç§’) | 1åˆ† | 90æ—¥ |
| **ãƒªã‚½ãƒ¼ã‚¹** | `db_active_transactions` | ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³æ•° | 15ç§’ | 7æ—¥ |
| **ãƒªã‚½ãƒ¼ã‚¹** | `db_locks_count` | ãƒ­ãƒƒã‚¯æ•° | 15ç§’ | 7æ—¥ |

#### 3.1.4 Redisãƒ¡ãƒˆãƒªã‚¯ã‚¹

| ã‚«ãƒ†ã‚´ãƒª | ãƒ¡ãƒˆãƒªã‚¯ã‚¹å | èª¬æ˜ | åé›†é–“éš” | ä¿å­˜æœŸé–“ |
|---------|------------|------|---------|---------|
| **ãƒ¡ãƒ¢ãƒª** | `redis_memory_used_mb` | Redisä½¿ç”¨ãƒ¡ãƒ¢ãƒª (MB) | 15ç§’ | 30æ—¥ |
| **ãƒ¡ãƒ¢ãƒª** | `redis_memory_fragmentation_ratio` | ãƒ¡ãƒ¢ãƒªãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æ¯”ç‡ | 1åˆ† | 30æ—¥ |
| **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹** | `redis_commands_per_second` | ç§’é–“ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œæ•° | 15ç§’ | 7æ—¥ |
| **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹** | `redis_hit_rate` | ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ (%) | 1åˆ† | 30æ—¥ |
| **æ¥ç¶š** | `redis_connected_clients` | æ¥ç¶šä¸­ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ•° | 15ç§’ | 7æ—¥ |
| **æ¥ç¶š** | `redis_blocked_clients` | ãƒ–ãƒ­ãƒƒã‚¯ä¸­ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ•° | 15ç§’ | 7æ—¥ |

#### 3.1.5 AI Providerãƒ¡ãƒˆãƒªã‚¯ã‚¹

| ã‚«ãƒ†ã‚´ãƒª | ãƒ¡ãƒˆãƒªã‚¯ã‚¹å | èª¬æ˜ | åé›†é–“éš” | ä¿å­˜æœŸé–“ |
|---------|------------|------|---------|---------|
| **ãƒªã‚¯ã‚¨ã‚¹ãƒˆ** | `ai_request_count` | AIãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•° | 15ç§’ | 90æ—¥ |
| **ãƒªã‚¯ã‚¨ã‚¹ãƒˆ** | `ai_request_duration_ms` | AIå¿œç­”æ™‚é–“ (ms) - P50/P95/P99 | 15ç§’ | 90æ—¥ |
| **ãƒªã‚¯ã‚¨ã‚¹ãƒˆ** | `ai_error_count` | AIã‚¨ãƒ©ãƒ¼æ•° | 15ç§’ | 90æ—¥ |
| **ãƒªã‚¯ã‚¨ã‚¹ãƒˆ** | `ai_rate_limit_count` | ãƒ¬ãƒ¼ãƒˆåˆ¶é™ç™ºç”Ÿå›æ•° | 1åˆ† | 90æ—¥ |
| **ã‚³ã‚¹ãƒˆ** | `ai_token_usage_total` | ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ (ç´¯è¨ˆ) | 1æ™‚é–“ | 365æ—¥ |
| **ã‚³ã‚¹ãƒˆ** | `ai_estimated_cost_usd` | æ¨å®šã‚³ã‚¹ãƒˆ (USD) | 1æ™‚é–“ | 365æ—¥ |

### 3.2 ã‚¢ãƒ©ãƒ¼ãƒˆé–¾å€¤æ¨å¥¨å€¤

#### 3.2.1 é‡è¦åº¦ãƒ¬ãƒ™ãƒ«å®šç¾©

| é‡è¦åº¦ | ãƒ¬ãƒ™ãƒ« | å¯¾å¿œæ™‚é–“ | é€šçŸ¥å…ˆ |
|-------|-------|---------|-------|
| **P1 - Critical** | ã‚·ã‚¹ãƒ†ãƒ åœæ­¢ã€ãƒ‡ãƒ¼ã‚¿æå¤±ãƒªã‚¹ã‚¯ | å³åº§ (15åˆ†ä»¥å†…) | SREãƒãƒ¼ãƒ  + ç®¡ç†è€… + Slack/Teams |
| **P2 - High** | æ©Ÿèƒ½åˆ¶é™ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è‘—ã—ã„ä½ä¸‹ | 1æ™‚é–“ä»¥å†… | SREãƒãƒ¼ãƒ  + Slack/Teams |
| **P3 - Medium** | éƒ¨åˆ†çš„ãªæ©Ÿèƒ½ä½ä¸‹ | 4æ™‚é–“ä»¥å†… | SREãƒãƒ¼ãƒ  + Slack |
| **P4 - Low** | è­¦å‘Šãƒ¬ãƒ™ãƒ«ã€äºˆé˜²çš„æªç½® | ç¿Œå–¶æ¥­æ—¥ | Slack (é€šçŸ¥ã®ã¿) |

#### 3.2.2 ã‚¢ãƒ©ãƒ¼ãƒˆé–¾å€¤è¨­å®š

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | Warning (P4) | High (P3) | Critical (P2) | Emergency (P1) |
|-----------|-------------|-----------|--------------|---------------|
| **CPUä½¿ç”¨ç‡** | 70% (5åˆ†é–“) | 80% (5åˆ†é–“) | 90% (3åˆ†é–“) | 95% (1åˆ†é–“) |
| **ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡** | 75% (5åˆ†é–“) | 85% (5åˆ†é–“) | 90% (3åˆ†é–“) | 95% (1åˆ†é–“) |
| **ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡** | 70% | 80% | 90% | 95% |
| **APIå¿œç­”æ™‚é–“ (P95)** | 1000ms | 2000ms | 3000ms | 5000ms |
| **APIå¿œç­”æ™‚é–“ (P99)** | 2000ms | 3000ms | 5000ms | 10000ms |
| **APIã‚¨ãƒ©ãƒ¼ç‡** | 1% (5åˆ†é–“) | 3% (5åˆ†é–“) | 5% (3åˆ†é–“) | 10% (1åˆ†é–“) |
| **DBæ¥ç¶šãƒ—ãƒ¼ãƒ«ä½¿ç”¨ç‡** | 70% | 85% | 95% | 100% |
| **DBã‚¯ã‚¨ãƒªæ™‚é–“ (P95)** | 500ms | 1000ms | 2000ms | 5000ms |
| **Redis ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡** | 70% | 80% | 90% | 95% |
| **Redisã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡** | <80% (10åˆ†é–“) | <70% (10åˆ†é–“) | <60% (5åˆ†é–“) | <50% (3åˆ†é–“) |
| **WebSocketæ¥ç¶šæ•°** | - | - | 1000 (åŒæ™‚æ¥ç¶š) | 1500 (åŒæ™‚æ¥ç¶š) |
| **AIå¿œç­”æ™‚é–“ (P95)** | 3000ms | 5000ms | 10000ms | 15000ms |
| **AIã‚¨ãƒ©ãƒ¼ç‡** | 2% (10åˆ†é–“) | 5% (10åˆ†é–“) | 10% (5åˆ†é–“) | 20% (3åˆ†é–“) |
| **è¨¼æ˜æ›¸æœ‰åŠ¹æœŸé™** | 30æ—¥ä»¥å†… | 14æ—¥ä»¥å†… | 7æ—¥ä»¥å†… | 3æ—¥ä»¥å†… |

### 3.3 Slack/Teamsé€šçŸ¥è¨­å®š

#### 3.3.1 Slack Webhookè¨­å®š

**1. Slack Appã®ä½œæˆ:**
```
1. https://api.slack.com/apps ã«ã‚¢ã‚¯ã‚»ã‚¹
2. "Create New App" â†’ "From scratch"
3. Appå: "AI Interviewer Monitoring"
4. Workspaceé¸æŠ
```

**2. Incoming Webhookã®æœ‰åŠ¹åŒ–:**
```
1. "Incoming Webhooks" ã‚’ã‚¯ãƒªãƒƒã‚¯
2. "Activate Incoming Webhooks" ã‚’ã‚ªãƒ³ã«
3. "Add New Webhook to Workspace"
4. é€šçŸ¥å…ˆãƒãƒ£ãƒ³ãƒãƒ«é¸æŠ (ä¾‹: #ai-interviewer-alerts)
5. Webhook URLã‚’ã‚³ãƒ”ãƒ¼ (ä¾‹: https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXX)
```

**3. ç’°å¢ƒå¤‰æ•°ã«è¨­å®š:**
```bash
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL
```

**4. é€šçŸ¥ãƒ†ã‚¹ãƒˆ:**
```bash
curl -X POST "${SLACK_WEBHOOK_URL}" \
  -H 'Content-Type: application/json' \
  -d '{
    "text": "ğŸ§ª Test Alert from AI Interview System",
    "blocks": [
      {
        "type": "section",
        "text": {
          "type": "mrkdwn",
          "text": "*Test Alert*\nThis is a test message from AI Interview System monitoring."
        }
      }
    ]
  }'
```

#### 3.3.2 Microsoft Teams Webhookè¨­å®š

**1. Teams Connectorã®è¿½åŠ :**
```
1. Teamsãƒãƒ£ãƒ³ãƒãƒ«ã‚’é–‹ã (ä¾‹: AI Interviewer Alerts)
2. ãƒãƒ£ãƒ³ãƒãƒ«åã® [...] â†’ "Connectors"
3. "Incoming Webhook" ã‚’æ¤œç´¢ â†’ "Configure"
4. åå‰: "AI Interviewer Monitoring"
5. ã‚¢ã‚¤ã‚³ãƒ³ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
6. "Create"
7. Webhook URLã‚’ã‚³ãƒ”ãƒ¼
```

**2. ç’°å¢ƒå¤‰æ•°ã«è¨­å®š:**
```bash
TEAMS_WEBHOOK_URL=https://outlook.office.com/webhook/YOUR/WEBHOOK/URL
```

**3. é€šçŸ¥ãƒ†ã‚¹ãƒˆ:**
```bash
curl -X POST "${TEAMS_WEBHOOK_URL}" \
  -H 'Content-Type: application/json' \
  -d '{
    "@type": "MessageCard",
    "@context": "https://schema.org/extensions",
    "summary": "Test Alert",
    "themeColor": "0078D4",
    "title": "ğŸ§ª Test Alert from AI Interview System",
    "sections": [
      {
        "activityTitle": "Test Message",
        "text": "This is a test message from AI Interview System monitoring.",
        "facts": [
          {
            "name": "Environment:",
            "value": "Production"
          },
          {
            "name": "Timestamp:",
            "value": "2026-02-15T10:30:00Z"
          }
        ]
      }
    ]
  }'
```

#### 3.3.3 ã‚¢ãƒ©ãƒ¼ãƒˆé€šçŸ¥ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹

**Critical Alert (P1) - Slack:**
```json
{
  "text": "ğŸš¨ CRITICAL: API Backend Down",
  "blocks": [
    {
      "type": "header",
      "text": {
        "type": "plain_text",
        "text": "ğŸš¨ CRITICAL ALERT (P1)"
      }
    },
    {
      "type": "section",
      "fields": [
        {
          "type": "mrkdwn",
          "text": "*Service:*\nAPI Backend"
        },
        {
          "type": "mrkdwn",
          "text": "*Status:*\nDown"
        },
        {
          "type": "mrkdwn",
          "text": "*Environment:*\nProduction"
        },
        {
          "type": "mrkdwn",
          "text": "*Time:*\n2026-02-15 10:30:00 JST"
        }
      ]
    },
    {
      "type": "section",
      "text": {
        "type": "mrkdwn",
        "text": "*Error:* Health check endpoint /api/v1/health returned HTTP 503"
      }
    },
    {
      "type": "section",
      "text": {
        "type": "mrkdwn",
        "text": "*Action Required:* Check container logs and restart if necessary\n`docker logs ai-interviewer-api`"
      }
    },
    {
      "type": "actions",
      "elements": [
        {
          "type": "button",
          "text": {
            "type": "plain_text",
            "text": "View Logs"
          },
          "url": "https://logs.example.com/api-backend"
        },
        {
          "type": "button",
          "text": {
            "type": "plain_text",
            "text": "View Dashboard"
          },
          "url": "https://monitoring.example.com/dashboard"
        }
      ]
    }
  ]
}
```

---

## 4. ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œ

### 4.1 éšœå®³ãƒ¬ãƒ™ãƒ«å®šç¾©

| ãƒ¬ãƒ™ãƒ« | å®šç¾© | å½±éŸ¿ç¯„å›² | å¯¾å¿œæ™‚é–“ | ä¾‹ |
|-------|------|---------|---------|---|
| **P1 - Critical** | ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“åœæ­¢ã€é‡å¤§ãªã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¾µå®³ | å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ | å³åº§ (15åˆ†ä»¥å†…) | APIå…¨åœæ­¢ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åœæ­¢ã€æƒ…å ±æ¼æ´© |
| **P2 - High** | ä¸»è¦æ©Ÿèƒ½åœæ­¢ã€é‡å¤§ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä½ä¸‹ | å¤šæ•°ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ | 1æ™‚é–“ä»¥å†… | é¢æ¥ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ä¸å¯ã€èªè¨¼æ©Ÿèƒ½åœæ­¢ |
| **P3 - Medium** | éƒ¨åˆ†çš„ãªæ©Ÿèƒ½åœæ­¢ã€è»½å¾®ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä½ä¸‹ | ä¸€éƒ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ | 4æ™‚é–“ä»¥å†… | ç‰¹å®šæ©Ÿèƒ½ã®ã‚¨ãƒ©ãƒ¼ã€å¿œç­”é…å»¶ |
| **P4 - Low** | è»½å¾®ãªå•é¡Œã€å°†æ¥çš„ãªå•é¡Œã®äºˆå…† | é™å®šçš„ | ç¿Œå–¶æ¥­æ—¥ | ãƒ­ã‚°è­¦å‘Šã€ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨ç‡ä¸Šæ˜‡ |

### 4.2 ã‚ˆãã‚ã‚‹éšœå®³ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨å¯¾å‡¦æ³•

#### 4.2.1 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ

**ç—‡çŠ¶:**
```
Error: asyncpg.exceptions.ConnectionTimeoutError: timeout acquiring a connection from the pool
```

**åŸå› :**
- DBæ¥ç¶šãƒ—ãƒ¼ãƒ«ã®æ¯æ¸‡
- é•·æ™‚é–“å®Ÿè¡Œã•ã‚Œã‚‹ã‚¯ã‚¨ãƒªã«ã‚ˆã‚‹ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³å æœ‰
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µãƒ¼ãƒãƒ¼ã®é«˜è² è·

**ç¢ºèªæ‰‹é †:**
```bash
# 1. ç¾åœ¨ã®æ¥ç¶šãƒ—ãƒ¼ãƒ«çŠ¶æ…‹ã‚’ç¢ºèª
curl https://api.example.com/api/v1/health | jq '.checks.database.connection_pool'

# 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ç¾åœ¨ã®æ¥ç¶šæ•°ã‚’ç¢ºèª
docker exec -it postgres psql -U postgres -d ai_interviewer -c \
  "SELECT count(*) FROM pg_stat_activity WHERE datname = 'ai_interviewer';"

# 3. é•·æ™‚é–“å®Ÿè¡Œä¸­ã®ã‚¯ã‚¨ãƒªã‚’ç¢ºèª
docker exec -it postgres psql -U postgres -d ai_interviewer -c \
  "SELECT pid, now() - query_start as duration, query FROM pg_stat_activity
   WHERE state = 'active' AND now() - query_start > interval '5 seconds'
   ORDER BY duration DESC;"
```

**å¯¾å‡¦æ³•:**

**å³åº§ã®å¯¾å¿œ:**
```bash
# 1. é•·æ™‚é–“å®Ÿè¡Œä¸­ã®ã‚¯ã‚¨ãƒªã‚’å¼·åˆ¶çµ‚äº† (æ…é‡ã«å®Ÿè¡Œ)
docker exec -it postgres psql -U postgres -d ai_interviewer -c \
  "SELECT pg_terminate_backend(pid) FROM pg_stat_activity
   WHERE state = 'active' AND now() - query_start > interval '30 seconds'
   AND query NOT LIKE '%pg_stat_activity%';"

# 2. APIã‚µãƒ¼ãƒãƒ¼ã‚’å†èµ·å‹• (æ¥ç¶šãƒ—ãƒ¼ãƒ«ã‚’ãƒªã‚»ãƒƒãƒˆ)
docker restart ai-interviewer-api

# 3. æ¥ç¶šãƒ—ãƒ¼ãƒ«ã‚µã‚¤ã‚ºã‚’ä¸€æ™‚çš„ã«å¢—ã‚„ã™ (ç’°å¢ƒå¤‰æ•°ã‚’æ›´æ–°ã—ã¦å†èµ·å‹•)
# DATABASE_POOL_SIZE=30 (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ20ã‹ã‚‰å¢—åŠ )
```

**æ’ä¹…çš„ãªå¯¾å¿œ:**
```bash
# 1. ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªãƒ­ã‚°ã‚’æœ‰åŠ¹åŒ–ã—ã¦ã‚¯ã‚¨ãƒªæœ€é©åŒ–
# postgresql.conf ã«è¿½åŠ :
# log_min_duration_statement = 1000  # 1ç§’ä»¥ä¸Šã®ã‚¯ã‚¨ãƒªã‚’ãƒ­ã‚°

# 2. æ¥ç¶šãƒ—ãƒ¼ãƒ«ã‚µã‚¤ã‚ºã®èª¿æ•´
# .env ãƒ•ã‚¡ã‚¤ãƒ«:
DATABASE_POOL_SIZE=30
DATABASE_MAX_OVERFLOW=20

# 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®è¿½åŠ  (ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªã«åŸºã¥ã)
```

#### 4.2.2 Redisæ¥ç¶šæ–­

**ç—‡çŠ¶:**
```
Error: redis.exceptions.ConnectionError: Error while reading from socket: ('Connection lost',)
```

**åŸå› :**
- Redisã‚µãƒ¼ãƒãƒ¼ã®å†èµ·å‹•
- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¸å®‰å®š
- Redisãƒ¡ãƒ¢ãƒªä¸è¶³ã«ã‚ˆã‚‹ã‚¯ãƒ©ãƒƒã‚·ãƒ¥
- maxclientsåˆ¶é™åˆ°é”

**ç¢ºèªæ‰‹é †:**
```bash
# 1. Redisã‚µãƒ¼ãƒãƒ¼ã®çŠ¶æ…‹ç¢ºèª
docker exec -it redis redis-cli ping
# æœŸå¾…ã•ã‚Œã‚‹å¿œç­”: PONG

# 2. Redisæ¥ç¶šæ•°ç¢ºèª
docker exec -it redis redis-cli INFO clients

# 3. Redisãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³ç¢ºèª
docker exec -it redis redis-cli INFO memory

# 4. Redisè¨­å®šç¢ºèª
docker exec -it redis redis-cli CONFIG GET maxmemory
docker exec -it redis redis-cli CONFIG GET maxclients
```

**å¯¾å‡¦æ³•:**

**å³åº§ã®å¯¾å¿œ:**
```bash
# 1. Redisã‚µãƒ¼ãƒãƒ¼å†èµ·å‹•
docker restart redis

# 2. Redisæ¥ç¶šã®ã‚¯ãƒªã‚¢
docker exec -it redis redis-cli CLIENT LIST
docker exec -it redis redis-cli CLIENT KILL TYPE normal  # é€šå¸¸æ¥ç¶šã‚’ã‚¯ãƒªã‚¢

# 3. APIã‚µãƒ¼ãƒãƒ¼å†èµ·å‹• (Rediså†æ¥ç¶š)
docker restart ai-interviewer-api
```

**æ’ä¹…çš„ãªå¯¾å¿œ:**
```bash
# 1. Redisãƒ¡ãƒ¢ãƒªåˆ¶é™ã®å¢—åŠ 
# redis.conf:
maxmemory 2gb
maxmemory-policy allkeys-lru

# 2. Redis Sentinel / Clusteræ§‹æˆã®å°å…¥ (é«˜å¯ç”¨æ€§)

# 3. æ¥ç¶šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šã®èª¿æ•´
# .env ãƒ•ã‚¡ã‚¤ãƒ«:
REDIS_SOCKET_TIMEOUT=10
REDIS_MAX_CONNECTIONS=100
```

#### 4.2.3 AI API Rate Limit

**ç—‡çŠ¶:**
```
Error: openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-xxx
```

**åŸå› :**
- AIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™è¶…é
- æƒ³å®šä»¥ä¸Šã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°
- ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ã®ä¸å‚™

**ç¢ºèªæ‰‹é †:**
```bash
# 1. ç¾åœ¨ã®AIä½¿ç”¨çŠ¶æ³ç¢ºèª
curl https://api.example.com/api/v1/health | jq '.checks.ai_provider'

# 2. éå»1æ™‚é–“ã®AIãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ç¢ºèª
docker logs --since "1h" ai-interviewer-api | grep '^{' | \
  jq -r 'select(.module == "ai_provider") | .message' | \
  grep -c "AI request"

# 3. ã‚¨ãƒ©ãƒ¼ç‡ã®ç¢ºèª
docker logs --since "1h" ai-interviewer-api | grep '^{' | \
  jq -r 'select(.level == "ERROR" and .message | contains("RateLimitError"))' | wc -l
```

**å¯¾å‡¦æ³•:**

**å³åº§ã®å¯¾å¿œ:**
```bash
# 1. ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚­ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚°ã®æœ‰åŠ¹åŒ– (ä¸€æ™‚çš„ãªåˆ¶é™)
# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šã§åŒæ™‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã‚’åˆ¶é™

# 2. ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯AIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã¸ã®åˆ‡ã‚Šæ›¿ãˆ
# ä¾‹: Azure OpenAI â†’ AWS Bedrock
# ç’°å¢ƒå¤‰æ•°ã‚’æ›´æ–°:
AI_PROVIDER=aws_bedrock

# 3. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æ´»ç”¨ (åŒã˜è³ªå•ã®å†åˆ©ç”¨)
```

**æ’ä¹…çš„ãªå¯¾å¿œ:**
```bash
# 1. ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’è€ƒæ…®ã—ãŸãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯å®Ÿè£…
# Exponential backoff + jitter

# 2. AIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ã‚¯ã‚©ãƒ¼ã‚¿å¢—åŠ ç”³è«‹

# 3. ãƒãƒ«ãƒãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼æ§‹æˆ (è² è·åˆ†æ•£)
# Azure OpenAI + AWS Bedrock + GCP Vertex AI

# 4. ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°/ã‚­ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ å°å…¥
# Redis Queue / Celery ç­‰
```

#### 4.2.4 WebSocketåˆ‡æ–­é »ç™º

**ç—‡çŠ¶:**
```
Warning: WebSocket connection closed unexpectedly
Error: WebSocket ping timeout
```

**åŸå› :**
- ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
- ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¸å®‰å®š
- ã‚µãƒ¼ãƒãƒ¼å´ã®ãƒªã‚½ãƒ¼ã‚¹ä¸è¶³
- Heartbeatè¨­å®šã®ä¸å‚™

**ç¢ºèªæ‰‹é †:**
```bash
# 1. ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªWebSocketæ¥ç¶šæ•°ç¢ºèª
curl https://api.example.com/api/v1/health | jq '.checks.websocket.active_connections'

# 2. éå»1æ™‚é–“ã®åˆ‡æ–­ãƒ­ã‚°ç¢ºèª
docker logs --since "1h" ai-interviewer-api | grep '^{' | \
  jq -r 'select(.message | contains("WebSocket disconnect"))' | \
  jq -r '[.timestamp, .context.disconnect_reason] | @tsv'

# 3. ã‚µãƒ¼ãƒãƒ¼ãƒªã‚½ãƒ¼ã‚¹ç¢ºèª
docker stats ai-interviewer-api --no-stream
```

**å¯¾å‡¦æ³•:**

**å³åº§ã®å¯¾å¿œ:**
```bash
# 1. ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šç¢ºèªãƒ»å»¶é•·
# AWS ALBä¾‹:
aws elbv2 modify-target-group-attributes \
  --target-group-arn arn:aws:elasticloadbalancing:... \
  --attributes Key=deregistration_delay.timeout_seconds,Value=300

# 2. Heartbeaté–“éš”ã®èª¿æ•´
# .env ãƒ•ã‚¡ã‚¤ãƒ«:
WS_HEARTBEAT_INTERVAL=20  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ30ç§’ã‹ã‚‰çŸ­ç¸®

# 3. å†æ¥ç¶šãƒ­ã‚¸ãƒƒã‚¯ã®ç¢ºèª (ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´)
```

**æ’ä¹…çš„ãªå¯¾å¿œ:**
```bash
# 1. WebSocketãƒ—ãƒ­ã‚­ã‚·è¨­å®šæœ€é©åŒ–
# nginx.confä¾‹:
proxy_read_timeout 3600s;
proxy_send_timeout 3600s;
proxy_http_version 1.1;
proxy_set_header Upgrade $http_upgrade;
proxy_set_header Connection "upgrade";

# 2. WebSocketå°‚ç”¨ã‚µãƒ¼ãƒãƒ¼ã®åˆ†é›¢

# 3. æ¥ç¶šç®¡ç†ã®æ”¹å–„
# - è‡ªå‹•å†æ¥ç¶šæ©Ÿèƒ½
# - ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®æ°¸ç¶šåŒ–
# - ã‚°ãƒ¬ãƒ¼ã‚¹ãƒ•ãƒ«ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³
```

### 4.3 ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ãƒ­ãƒ¼

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç™ºç”Ÿ                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Level 1: è‡ªå‹•ã‚¢ãƒ©ãƒ¼ãƒˆæ¤œçŸ¥ â†’ Slack/Teamsé€šçŸ¥                 â”‚
â”‚   æ‹…å½“: ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ                                           â”‚
â”‚   ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: åˆå‹•å¯¾å¿œ (ãƒ­ã‚°ç¢ºèªã€å†èµ·å‹•ç­‰)                     â”‚
â”‚   æ™‚é–“: å³åº§ï½15åˆ†                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ 15åˆ†ä»¥å†…ã«è§£æ±ºã—ãªã„å ´åˆ
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Level 2: ã‚ªãƒ³ã‚³ãƒ¼ãƒ«SREã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢                             â”‚
â”‚   æ‹…å½“: SREãƒãƒ¼ãƒ  (äº¤ä»£åˆ¶)                                     â”‚
â”‚   ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: è©³ç´°èª¿æŸ»ã€ç·Šæ€¥å¯¾å¿œã€å›é¿ç­–å®Ÿæ–½                     â”‚
â”‚   æ™‚é–“: 15åˆ†ï½1æ™‚é–“                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ P1/P2ã§1æ™‚é–“ä»¥å†…ã«è§£æ±ºã—ãªã„å ´åˆ
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Level 3: ã‚·ãƒ‹ã‚¢SRE + é–‹ç™ºãƒãƒ¼ãƒ ãƒªãƒ¼ãƒ‰                        â”‚
â”‚   æ‹…å½“: ã‚·ãƒ‹ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ + ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆ                         â”‚
â”‚   ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: æ ¹æœ¬åŸå› åˆ†æã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¬ãƒ™ãƒ«ã®å¯¾å¿œ            â”‚
â”‚   æ™‚é–“: 1æ™‚é–“ï½4æ™‚é–“                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ P1ã§4æ™‚é–“ä»¥å†…ã«è§£æ±ºã—ãªã„å ´åˆ
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Level 4: çµŒå–¶å±¤ + ãƒ™ãƒ³ãƒ€ãƒ¼ã‚µãƒãƒ¼ãƒˆ                           â”‚
â”‚   æ‹…å½“: CTO/VPoE + å¤–éƒ¨å°‚é–€å®¶                                 â”‚
â”‚   ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: çµŒå–¶åˆ¤æ–­ã€é¡§å®¢ã¸ã®å…¬å¼ã‚¢ãƒŠã‚¦ãƒ³ã‚¹ã€å¤–éƒ¨æ”¯æ´è¦è«‹      â”‚
â”‚   æ™‚é–“: 4æ™‚é–“ä»¥é™                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**é€£çµ¡å…ˆãƒªã‚¹ãƒˆ (ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ):**

| Level | å½¹å‰² | æ‹…å½“è€… | é€£çµ¡å…ˆ | å¯¾å¿œæ™‚é–“ |
|-------|------|--------|--------|---------|
| L1 | ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ  | è‡ªå‹• | Slack: #ai-interviewer-alerts | 24/7 |
| L2 | ã‚ªãƒ³ã‚³ãƒ¼ãƒ«SRE | [åå‰] | Email: sre@example.com / Tel: xxx-xxxx-xxxx | 24/7 (äº¤ä»£åˆ¶) |
| L3 | ã‚·ãƒ‹ã‚¢SRE | [åå‰] | Email: senior-sre@example.com / Tel: xxx-xxxx-xxxx | å¹³æ—¥9-21æ™‚ |
| L3 | é–‹ç™ºãƒªãƒ¼ãƒ‰ | [åå‰] | Email: dev-lead@example.com / Tel: xxx-xxxx-xxxx | å¹³æ—¥9-21æ™‚ |
| L4 | CTO | [åå‰] | Email: cto@example.com / Tel: xxx-xxxx-xxxx | ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰ |

---

## 5. ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

### 5.1 æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒ« (Horizontal Scaling)

#### 5.1.1 APIãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

**ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°åˆ¤æ–­åŸºæº–:**
- CPUä½¿ç”¨ç‡ãŒ70%ã‚’è¶…ãˆãŸçŠ¶æ…‹ãŒ5åˆ†ä»¥ä¸Šç¶™ç¶š
- APIå¿œç­”æ™‚é–“P95ãŒ1000msã‚’è¶…ãˆã‚‹
- ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚­ãƒ¥ãƒ¼ãŒæºœã¾ã‚Šå§‹ã‚ã‚‹

**Docker Composeã§ã®ã‚¹ã‚±ãƒ¼ãƒ«ä¾‹:**
```bash
# ç¾åœ¨ã®çŠ¶æ…‹ç¢ºèª
docker-compose ps

# APIãƒ¬ãƒ—ãƒªã‚«ã‚’3å°ã«å¢—ã‚„ã™
docker-compose up -d --scale api=3

# ç¢ºèª
docker-compose ps api
```

**Kubernetes (HPA) ã§ã®ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒ«è¨­å®š:**
```yaml
# api-hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ai-interviewer-api-hpa
  namespace: ai-interviewer
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ai-interviewer-api
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  - type: Pods
    pods:
      metric:
        name: api_request_duration_ms_p95
      target:
        type: AverageValue
        averageValue: "1000"
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 25
        periodSeconds: 60
```

**é©ç”¨:**
```bash
kubectl apply -f api-hpa.yaml

# HPAçŠ¶æ…‹ç¢ºèª
kubectl get hpa -n ai-interviewer

# è©³ç´°ç¢ºèª
kubectl describe hpa ai-interviewer-api-hpa -n ai-interviewer
```

#### 5.1.2 Webãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

**Next.js ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°:**
```yaml
# web-hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ai-interviewer-web-hpa
  namespace: ai-interviewer
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ai-interviewer-web
  minReplicas: 2
  maxReplicas: 8
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 60
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 75
```

**CDNæ´»ç”¨ã«ã‚ˆã‚‹ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£å‘ä¸Š:**
```bash
# é™çš„ã‚¢ã‚»ãƒƒãƒˆ (ç”»åƒã€CSSã€JS) ã‚’CDNã«ã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰
# CloudFront / Cloudflare / Fastly ç­‰

# Next.jsè¨­å®šä¾‹ (next.config.js):
module.exports = {
  assetPrefix: process.env.CDN_URL || '',
  images: {
    domains: ['cdn.example.com'],
  },
}
```

### 5.2 å‚ç›´ã‚¹ã‚±ãƒ¼ãƒ« (Vertical Scaling)

#### 5.2.1 PostgreSQLã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

**ãƒªã‚½ãƒ¼ã‚¹å¢—å¼·ã®åˆ¤æ–­åŸºæº–:**
- CPUä½¿ç”¨ç‡ãŒ80%ã‚’è¶…ãˆã‚‹
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒ85%ã‚’è¶…ãˆã‚‹
- ãƒ‡ã‚£ã‚¹ã‚¯I/Oå¾…ã¡ãŒç™ºç”Ÿ

**Docker Composeã§ã®ãƒªã‚½ãƒ¼ã‚¹èª¿æ•´:**
```yaml
# docker-compose.yml
services:
  postgres:
    image: postgres:15
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G
        reservations:
          cpus: '2.0'
          memory: 4G
    environment:
      POSTGRES_SHARED_BUFFERS: 2GB
      POSTGRES_EFFECTIVE_CACHE_SIZE: 6GB
      POSTGRES_WORK_MEM: 64MB
      POSTGRES_MAINTENANCE_WORK_MEM: 512MB
```

**PostgreSQLè¨­å®šæœ€é©åŒ– (postgresql.conf):**
```conf
# ãƒ¡ãƒ¢ãƒªè¨­å®š (ã‚µãƒ¼ãƒãƒ¼ãƒ¡ãƒ¢ãƒª8GBã®å ´åˆ)
shared_buffers = 2GB
effective_cache_size = 6GB
work_mem = 64MB
maintenance_work_mem = 512MB

# æ¥ç¶šè¨­å®š
max_connections = 200

# WALè¨­å®š
wal_buffers = 16MB
checkpoint_completion_target = 0.9
max_wal_size = 2GB

# ã‚¯ã‚¨ãƒªãƒ—ãƒ©ãƒ³ãƒŠãƒ¼
random_page_cost = 1.1  # SSDä½¿ç”¨æ™‚
effective_io_concurrency = 200
```

**é©ç”¨:**
```bash
# PostgreSQLã‚³ãƒ³ãƒ†ãƒŠå†èµ·å‹•
docker-compose restart postgres

# è¨­å®šç¢ºèª
docker exec -it postgres psql -U postgres -c "SHOW shared_buffers;"
docker exec -it postgres psql -U postgres -c "SHOW max_connections;"
```

#### 5.2.2 Redisã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

**ãƒªã‚½ãƒ¼ã‚¹å¢—å¼·ã®åˆ¤æ–­åŸºæº–:**
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒ80%ã‚’è¶…ãˆã‚‹
- ãƒ¡ãƒ¢ãƒªãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æ¯”ç‡ãŒ1.5ã‚’è¶…ãˆã‚‹
- ã‚¹ãƒ¯ãƒƒãƒ—ä½¿ç”¨ãŒç™ºç”Ÿ

**Docker Composeã§ã®ãƒªã‚½ãƒ¼ã‚¹èª¿æ•´:**
```yaml
# docker-compose.yml
services:
  redis:
    image: redis:7
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    command: >
      redis-server
      --maxmemory 3gb
      --maxmemory-policy allkeys-lru
      --save ""
      --appendonly yes
```

**Redis Clusteræ§‹æˆ (é«˜å¯ç”¨æ€§ + ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£):**
```bash
# Redis Cluster 6ãƒãƒ¼ãƒ‰æ§‹æˆ (3 primary + 3 replica)
# docker-compose.cluster.yml
version: '3.8'
services:
  redis-node-1:
    image: redis:7
    command: redis-server --cluster-enabled yes --port 7001
    ports: ["7001:7001"]
  redis-node-2:
    image: redis:7
    command: redis-server --cluster-enabled yes --port 7002
    ports: ["7002:7002"]
  redis-node-3:
    image: redis:7
    command: redis-server --cluster-enabled yes --port 7003
    ports: ["7003:7003"]
  redis-node-4:
    image: redis:7
    command: redis-server --cluster-enabled yes --port 7004
    ports: ["7004:7004"]
  redis-node-5:
    image: redis:7
    command: redis-server --cluster-enabled yes --port 7005
    ports: ["7005:7005"]
  redis-node-6:
    image: redis:7
    command: redis-server --cluster-enabled yes --port 7006
    ports: ["7006:7006"]

# ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆæœŸåŒ–
docker exec -it redis-node-1 redis-cli --cluster create \
  redis-node-1:7001 redis-node-2:7002 redis-node-3:7003 \
  redis-node-4:7004 redis-node-5:7005 redis-node-6:7006 \
  --cluster-replicas 1
```

### 5.3 ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒ«è¨­å®šä¾‹

#### 5.3.1 AWS ECS Fargate ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒ«

```json
{
  "serviceArn": "arn:aws:ecs:ap-northeast-1:123456789012:service/ai-interviewer/api",
  "scalableTarget": {
    "minCapacity": 3,
    "maxCapacity": 10,
    "resourceId": "service/ai-interviewer/api",
    "scalableDimension": "ecs:service:DesiredCount"
  },
  "scalingPolicies": [
    {
      "policyName": "cpu-scale-up",
      "policyType": "TargetTrackingScaling",
      "targetTrackingScalingPolicyConfiguration": {
        "targetValue": 70.0,
        "predefinedMetricSpecification": {
          "predefinedMetricType": "ECSServiceAverageCPUUtilization"
        },
        "scaleOutCooldown": 60,
        "scaleInCooldown": 300
      }
    },
    {
      "policyName": "memory-scale-up",
      "policyType": "TargetTrackingScaling",
      "targetTrackingScalingPolicyConfiguration": {
        "targetValue": 80.0,
        "predefinedMetricSpecification": {
          "predefinedMetricType": "ECSServiceAverageMemoryUtilization"
        },
        "scaleOutCooldown": 60,
        "scaleInCooldown": 300
      }
    },
    {
      "policyName": "request-count-scale",
      "policyType": "TargetTrackingScaling",
      "targetTrackingScalingPolicyConfiguration": {
        "targetValue": 1000.0,
        "customizedMetricSpecification": {
          "metricName": "RequestCountPerTarget",
          "namespace": "AWS/ApplicationELB",
          "statistic": "Sum"
        },
        "scaleOutCooldown": 60,
        "scaleInCooldown": 300
      }
    }
  ]
}
```

#### 5.3.2 GCP Cloud Run ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒ«

```yaml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: ai-interviewer-api
  namespace: default
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/minScale: "3"
        autoscaling.knative.dev/maxScale: "10"
        autoscaling.knative.dev/target: "70"
        autoscaling.knative.dev/metric: "cpu"
    spec:
      containers:
      - image: gcr.io/project-id/ai-interviewer-api:latest
        resources:
          limits:
            cpu: "2"
            memory: "4Gi"
          requests:
            cpu: "1"
            memory: "2Gi"
        env:
        - name: ENVIRONMENT
          value: "production"
```

---

## 6. ãƒ‡ãƒ—ãƒ­ã‚¤é‹ç”¨

### 6.1 CI/CD (GitHub Actions)

#### 6.1.1 CI/CDãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ¦‚è¦

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Git Push (feature branch)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CI: Linting + Unit Tests                                   â”‚
â”‚  - ruff (Python), eslint (TypeScript)                       â”‚
â”‚  - pytest (backend), vitest (frontend)                      â”‚
â”‚  - ã‚«ãƒãƒ¬ãƒƒã‚¸80%ä»¥ä¸Šå¿…é ˆ                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Pull Requestä½œæˆ                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CI: Integration Tests                                      â”‚
â”‚  - APIçµ±åˆãƒ†ã‚¹ãƒˆ (pytest + httpx)                            â”‚
â”‚  - E2Eãƒ†ã‚¹ãƒˆ (Playwright)                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Code Review + Approval                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Merge to main branch                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CD: Build & Deploy to Staging                              â”‚
â”‚  - Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰                                       â”‚
â”‚  - Stagingã¸ãƒ‡ãƒ—ãƒ­ã‚¤                                          â”‚
â”‚  - Smoke Testå®Ÿè¡Œ                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Manual Approval (Stagingæ¤œè¨¼å®Œäº†)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CD: Deploy to Production                                   â”‚
â”‚  - Blue/Green Deployment                                    â”‚
â”‚  - Health Check                                             â”‚
â”‚  - Rollbackæº–å‚™å®Œäº†                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 6.1.2 GitHub Actionsè¨­å®š

**.github/workflows/ci.yml:**
```yaml
name: CI

on:
  push:
    branches: [main, develop, 'feature/**']
  pull_request:
    branches: [main, develop]

jobs:
  lint-backend:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          cd apps/backend
          pip install -r requirements.txt
          pip install ruff pytest pytest-cov
      - name: Run ruff
        run: cd apps/backend && ruff check .
      - name: Run ruff format check
        run: cd apps/backend && ruff format --check .

  lint-frontend:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: pnpm/action-setup@v2
        with:
          version: 8
      - uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'pnpm'
      - name: Install dependencies
        run: pnpm install
      - name: Run eslint
        run: pnpm lint
      - name: Run type check
        run: pnpm type-check

  test-backend:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          cd apps/backend
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-asyncio
      - name: Run tests
        env:
          DATABASE_URL: postgresql+asyncpg://postgres:testpass@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379/0
        run: |
          cd apps/backend
          pytest --cov=grc_backend --cov-report=xml --cov-report=term
      - name: Check coverage
        run: |
          cd apps/backend
          coverage report --fail-under=80

  test-frontend:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: pnpm/action-setup@v2
        with:
          version: 8
      - uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'pnpm'
      - name: Install dependencies
        run: pnpm install
      - name: Run unit tests
        run: pnpm test:unit
      - name: Check coverage
        run: pnpm test:coverage --reporter=text --reporter=json-summary

  e2e-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: pnpm/action-setup@v2
        with:
          version: 8
      - uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'pnpm'
      - name: Install dependencies
        run: pnpm install
      - name: Install Playwright
        run: pnpm exec playwright install --with-deps
      - name: Start services
        run: docker-compose up -d
      - name: Wait for services
        run: |
          timeout 60 bash -c 'until curl -f http://localhost:8001/api/v1/health; do sleep 2; done'
      - name: Run E2E tests
        run: pnpm test:e2e
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report
          path: playwright-report/
```

**.github/workflows/cd-staging.yml:**
```yaml
name: CD - Staging

on:
  push:
    branches: [main]

jobs:
  deploy-staging:
    runs-on: ubuntu-latest
    environment: staging
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-northeast-1

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build and push backend image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ai-interviewer-api
          IMAGE_TAG: ${{ github.sha }}
        run: |
          cd apps/backend
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
          docker tag $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY:staging
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:staging

      - name: Build and push frontend image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ai-interviewer-web
          IMAGE_TAG: ${{ github.sha }}
        run: |
          cd apps/web
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
          docker tag $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY:staging
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:staging

      - name: Deploy to ECS Staging
        run: |
          aws ecs update-service \
            --cluster ai-interviewer-staging \
            --service api \
            --force-new-deployment

          aws ecs update-service \
            --cluster ai-interviewer-staging \
            --service web \
            --force-new-deployment

      - name: Wait for deployment
        run: |
          aws ecs wait services-stable \
            --cluster ai-interviewer-staging \
            --services api web

      - name: Run smoke tests
        run: |
          curl -f https://staging-api.example.com/api/v1/health || exit 1
          curl -f https://staging.example.com/ || exit 1

      - name: Notify Slack
        if: always()
        uses: slackapi/slack-github-action@v1
        with:
          payload: |
            {
              "text": "Staging Deployment: ${{ job.status }}",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "*Staging Deployment ${{ job.status }}*\nCommit: ${{ github.sha }}\nAuthor: ${{ github.actor }}"
                  }
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
```

**.github/workflows/cd-production.yml:**
```yaml
name: CD - Production

on:
  workflow_dispatch:
    inputs:
      version:
        description: 'Version to deploy (git tag or commit SHA)'
        required: true

jobs:
  deploy-production:
    runs-on: ubuntu-latest
    environment: production
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.event.inputs.version }}

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-northeast-1

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Pull staging images
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        run: |
          docker pull $ECR_REGISTRY/ai-interviewer-api:staging
          docker pull $ECR_REGISTRY/ai-interviewer-web:staging

      - name: Tag for production
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          VERSION: ${{ github.event.inputs.version }}
        run: |
          docker tag $ECR_REGISTRY/ai-interviewer-api:staging $ECR_REGISTRY/ai-interviewer-api:$VERSION
          docker tag $ECR_REGISTRY/ai-interviewer-api:staging $ECR_REGISTRY/ai-interviewer-api:production
          docker tag $ECR_REGISTRY/ai-interviewer-web:staging $ECR_REGISTRY/ai-interviewer-web:$VERSION
          docker tag $ECR_REGISTRY/ai-interviewer-web:staging $ECR_REGISTRY/ai-interviewer-web:production

          docker push $ECR_REGISTRY/ai-interviewer-api:$VERSION
          docker push $ECR_REGISTRY/ai-interviewer-api:production
          docker push $ECR_REGISTRY/ai-interviewer-web:$VERSION
          docker push $ECR_REGISTRY/ai-interviewer-web:production

      - name: Deploy to ECS Production (Blue/Green)
        run: |
          # Blue/Green ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã®é–‹å§‹
          aws deploy create-deployment \
            --application-name ai-interviewer \
            --deployment-group-name production \
            --deployment-config-name CodeDeployDefault.ECSAllAtOnce \
            --description "Deploying version ${{ github.event.inputs.version }}"

      - name: Wait for deployment
        run: |
          # ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå®Œäº†å¾…æ©Ÿ (ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: 30åˆ†)
          timeout 1800 bash -c 'until aws ecs wait services-stable --cluster ai-interviewer-production --services api web; do sleep 10; done'

      - name: Health check
        run: |
          for i in {1..10}; do
            if curl -f https://api.example.com/api/v1/health; then
              echo "Health check passed"
              exit 0
            fi
            echo "Health check failed, retrying in 10s..."
            sleep 10
          done
          echo "Health check failed after 10 attempts"
          exit 1

      - name: Notify Slack
        if: always()
        uses: slackapi/slack-github-action@v1
        with:
          payload: |
            {
              "text": "Production Deployment: ${{ job.status }}",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "*Production Deployment ${{ job.status }}*\nVersion: ${{ github.event.inputs.version }}\nTriggered by: ${{ github.actor }}"
                  }
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
```

### 6.2 ãƒ‡ãƒ—ãƒ­ã‚¤æ‰‹é †

#### 6.2.1 Stagingç’°å¢ƒã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤

**è‡ªå‹•ãƒ‡ãƒ—ãƒ­ã‚¤ (main branchã¸ã®ãƒãƒ¼ã‚¸ã§è‡ªå‹•å®Ÿè¡Œ):**
```bash
# 1. feature branchã§é–‹ç™º
git checkout -b feature/new-feature

# 2. å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆ
git add .
git commit -m "Add new feature"

# 3. GitHub ã«push
git push origin feature/new-feature

# 4. Pull Requestä½œæˆ (GitHub UI)

# 5. CIé€šé & Code Reviewå®Œäº†å¾Œã€main ã¸ãƒãƒ¼ã‚¸
# â†’ è‡ªå‹•çš„ã«Stagingã¸ãƒ‡ãƒ—ãƒ­ã‚¤
```

**æ‰‹å‹•ç¢ºèª:**
```bash
# Stagingç’°å¢ƒã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
curl https://staging-api.example.com/api/v1/health

# Stagingã§ã®å‹•ä½œç¢ºèª
# - ãƒ­ã‚°ã‚¤ãƒ³æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
# - é¢æ¥ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ãƒ†ã‚¹ãƒˆ
# - WebSocketæ¥ç¶šãƒ†ã‚¹ãƒˆ
```

#### 6.2.2 Productionç’°å¢ƒã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤

**æ‰‹å‹•æ‰¿èªã«ã‚ˆã‚‹ãƒ‡ãƒ—ãƒ­ã‚¤:**
```bash
# 1. GitHub Actions ã® "CD - Production" ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ
# https://github.com/your-org/ai-interviewer/actions/workflows/cd-production.yml

# 2. "Run workflow" ã‚’ã‚¯ãƒªãƒƒã‚¯
# 3. ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å…¥åŠ› (ä¾‹: v1.2.3 ã¾ãŸã¯ commit SHA)
# 4. "Run workflow" ã§å®Ÿè¡Œé–‹å§‹

# 5. ãƒ‡ãƒ—ãƒ­ã‚¤ç›£è¦–
# GitHub Actions ã®ãƒ­ã‚°ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ç¢ºèª

# 6. ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº†å¾Œã€Health Check
curl https://api.example.com/api/v1/health

# 7. æœ¬ç•ªç’°å¢ƒã§ã®å‹•ä½œç¢ºèª
# - ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
# - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç¢ºèª
# - ãƒ­ã‚°ç›£è¦–
```

### 6.3 ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ‰‹é †

#### 6.3.1 ç·Šæ€¥ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ (Production)

**æ‰‹é †:**
```bash
# 1. ç¾åœ¨ã®ãƒ‡ãƒ—ãƒ­ã‚¤çŠ¶æ³ç¢ºèª
aws ecs describe-services \
  --cluster ai-interviewer-production \
  --services api web

# 2. ç›´å‰ã®å®‰å®šãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¢ºèª
aws ecr describe-images \
  --repository-name ai-interviewer-api \
  --query 'sort_by(imageDetails,& imagePushedAt)[-5:]'

# 3. ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ (å‰ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ã‚¿ã‚°ã«æˆ»ã™)
PREVIOUS_VERSION="v1.2.2"  # ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å…ˆã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³

# APIã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
aws ecs update-service \
  --cluster ai-interviewer-production \
  --service api \
  --task-definition ai-interviewer-api:$(aws ecs describe-task-definition --task-definition ai-interviewer-api --query 'taskDefinition.revision' --output text)

# ã‚¿ã‚¹ã‚¯å®šç¾©ã‚’å‰ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«æˆ»ã™
aws ecs register-task-definition \
  --cli-input-json file://task-definition-api-$PREVIOUS_VERSION.json

aws ecs update-service \
  --cluster ai-interviewer-production \
  --service api \
  --task-definition ai-interviewer-api:$(aws ecs describe-task-definition --task-definition ai-interviewer-api --query 'taskDefinition.revision' --output text) \
  --force-new-deployment

# 4. ã‚µãƒ¼ãƒ“ã‚¹å®‰å®šåŒ–å¾…æ©Ÿ
aws ecs wait services-stable \
  --cluster ai-interviewer-production \
  --services api web

# 5. Health Check
curl https://api.example.com/api/v1/health

# 6. Slacké€šçŸ¥
curl -X POST $SLACK_WEBHOOK_URL \
  -H 'Content-Type: application/json' \
  -d '{
    "text": "ğŸ”„ Rollback completed to version '"$PREVIOUS_VERSION"'",
    "blocks": [
      {
        "type": "section",
        "text": {
          "type": "mrkdwn",
          "text": "*Rollback Completed*\nVersion: '"$PREVIOUS_VERSION"'\nPerformed by: '"$USER"'"
        }
      }
    ]
  }'
```

#### 6.3.2 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯

**æ³¨æ„:** ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¯æ…é‡ã«è¡Œã†å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

```bash
# 1. ç¾åœ¨ã®ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çŠ¶æ…‹ç¢ºèª
docker exec -it ai-interviewer-api alembic current

# 2. ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å±¥æ­´ç¢ºèª
docker exec -it ai-interviewer-api alembic history

# 3. 1ã¤å‰ã®ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«æˆ»ã™
docker exec -it ai-interviewer-api alembic downgrade -1

# 4. ç‰¹å®šã®ãƒªãƒ“ã‚¸ãƒ§ãƒ³ã«æˆ»ã™
docker exec -it ai-interviewer-api alembic downgrade abc123def456

# 5. ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ç¢ºèª
docker exec -it postgres psql -U postgres -d ai_interviewer -c "SELECT COUNT(*) FROM users;"
docker exec -it postgres psql -U postgres -d ai_interviewer -c "SELECT COUNT(*) FROM interviews;"

# 6. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å†èµ·å‹•
docker restart ai-interviewer-api
```

---

## 7. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é‹ç”¨

### 7.1 è¨¼æ˜æ›¸æ›´æ–° (TLS)

#### 7.1.1 Let's Encryptè¨¼æ˜æ›¸ã®è‡ªå‹•æ›´æ–°

**Certbotè‡ªå‹•æ›´æ–°è¨­å®š:**
```bash
# Certbotã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« (Ubuntu/Debian)
sudo apt-get update
sudo apt-get install certbot python3-certbot-nginx

# è¨¼æ˜æ›¸å–å¾— (åˆå›)
sudo certbot --nginx -d api.example.com -d example.com

# è‡ªå‹•æ›´æ–°è¨­å®š (cron)
sudo crontab -e

# æ¯æ—¥2:30ã«è¨¼æ˜æ›¸æ›´æ–°ãƒã‚§ãƒƒã‚¯
30 2 * * * certbot renew --quiet --post-hook "systemctl reload nginx"
```

**è¨¼æ˜æ›¸æœ‰åŠ¹æœŸé™ãƒã‚§ãƒƒã‚¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆ:**
```bash
#!/bin/bash
# check_certificate.sh

DOMAIN="api.example.com"
SLACK_WEBHOOK="your-slack-webhook-url"
WARNING_DAYS=30

# è¨¼æ˜æ›¸ã®æœ‰åŠ¹æœŸé™ã‚’å–å¾—
expiry_date=$(echo | openssl s_client -servername $DOMAIN -connect $DOMAIN:443 2>/dev/null | openssl x509 -noout -enddate | cut -d= -f2)
expiry_epoch=$(date -d "$expiry_date" +%s)
current_epoch=$(date +%s)
days_remaining=$(( ($expiry_epoch - $current_epoch) / 86400 ))

echo "Certificate for $DOMAIN expires in $days_remaining days"

if [ $days_remaining -le $WARNING_DAYS ]; then
  severity="WARNING"
  icon="âš ï¸"

  if [ $days_remaining -le 7 ]; then
    severity="CRITICAL"
    icon="ğŸš¨"
  fi

  message="${icon} ${severity}: SSL Certificate for ${DOMAIN} expires in ${days_remaining} days"

  curl -X POST "$SLACK_WEBHOOK" \
    -H 'Content-Type: application/json' \
    -d "{
      \"text\": \"$message\",
      \"blocks\": [
        {
          \"type\": \"section\",
          \"text\": {
            \"type\": \"mrkdwn\",
            \"text\": \"*$message*\nExpiry Date: $expiry_date\"
          }
        }
      ]
    }"
fi
```

#### 7.1.2 ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰è¨¼æ˜æ›¸ã®ç®¡ç†

**AWS Certificate Manager (ACM) ã®å ´åˆ:**
```bash
# è¨¼æ˜æ›¸ãƒªã‚¹ãƒˆç¢ºèª
aws acm list-certificates --region ap-northeast-1

# è¨¼æ˜æ›¸è©³ç´°ç¢ºèª
aws acm describe-certificate \
  --certificate-arn arn:aws:acm:ap-northeast-1:123456789012:certificate/abc123 \
  --region ap-northeast-1

# è¨¼æ˜æ›¸æœ‰åŠ¹æœŸé™ãƒã‚§ãƒƒã‚¯ (CloudWatch Alarmã§è‡ªå‹•åŒ–æ¨å¥¨)
aws cloudwatch put-metric-alarm \
  --alarm-name acm-certificate-expiry \
  --alarm-description "Alert when ACM certificate is expiring" \
  --metric-name DaysToExpiry \
  --namespace AWS/CertificateManager \
  --statistic Minimum \
  --period 86400 \
  --evaluation-periods 1 \
  --threshold 30 \
  --comparison-operator LessThanThreshold \
  --alarm-actions arn:aws:sns:ap-northeast-1:123456789012:ops-alerts
```

### 7.2 APIã‚­ãƒ¼ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³

#### 7.2.1 JWT Secret Key ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³

**æ‰‹é †:**
```bash
# 1. æ–°ã—ã„JWT Secret Keyã‚’ç”Ÿæˆ
NEW_JWT_SECRET=$(openssl rand -hex 32)

# 2. ç’°å¢ƒå¤‰æ•°ã«ä¸¡æ–¹ã®ã‚­ãƒ¼ã‚’è¨­å®š (ä¸€æ™‚çš„ã«ãƒ‡ãƒ¥ã‚¢ãƒ«é‹ç”¨)
# .env.production:
JWT_SECRET_KEY=old-secret-key
JWT_SECRET_KEY_NEW=new-secret-key-generated-above

# 3. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å´ã§ä¸¡æ–¹ã®ã‚­ãƒ¼ã‚’æ¤œè¨¼ã§ãã‚‹ã‚ˆã†ã«å®Ÿè£…
# grc_backend/auth/jwt.py:
# - ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆ: æ–°ã‚­ãƒ¼ã‚’ä½¿ç”¨
# - ãƒˆãƒ¼ã‚¯ãƒ³æ¤œè¨¼: æ–°ã‚­ãƒ¼å„ªå…ˆã€å¤±æ•—ã—ãŸã‚‰æ—§ã‚­ãƒ¼ã§æ¤œè¨¼

# 4. ãƒ‡ãƒ—ãƒ­ã‚¤
docker-compose up -d

# 5. 1é€±é–“å¾Œã€æ—§ã‚­ãƒ¼ã‚’å‰Šé™¤ (å…¨ãƒˆãƒ¼ã‚¯ãƒ³ãŒæ–°ã‚­ãƒ¼ã§å†ç™ºè¡Œã•ã‚ŒãŸå¾Œ)
# .env.production:
JWT_SECRET_KEY=new-secret-key-generated-above
# JWT_SECRET_KEY_NEW ã‚’å‰Šé™¤

# 6. å†ãƒ‡ãƒ—ãƒ­ã‚¤
docker-compose up -d
```

#### 7.2.2 AI Provider API Key ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³

**Azure OpenAI API Key:**
```bash
# 1. Azure Portalã§æ–°ã—ã„ã‚­ãƒ¼ã‚’ç”Ÿæˆ
# Azure Portal â†’ Azure OpenAI ãƒªã‚½ãƒ¼ã‚¹ â†’ Keys and Endpoint â†’ Regenerate Key 2

# 2. ç’°å¢ƒå¤‰æ•°ã‚’æ›´æ–°
# .env.production:
AZURE_OPENAI_API_KEY=new-api-key-from-azure-portal

# 3. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å†èµ·å‹• (ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ãªã—)
docker-compose up -d --no-deps api

# 4. Health Check
curl https://api.example.com/api/v1/health | jq '.checks.ai_provider'

# 5. æ—§ã‚­ãƒ¼ã‚’ç„¡åŠ¹åŒ– (Azure Portal)
```

**AWS Bedrock Credentials:**
```bash
# 1. æ–°ã—ã„IAM Access Keyã‚’ç”Ÿæˆ
aws iam create-access-key --user-name ai-interviewer-service

# 2. ç’°å¢ƒå¤‰æ•°ã‚’æ›´æ–°
# .env.production:
AWS_ACCESS_KEY_ID=new-access-key-id
AWS_SECRET_ACCESS_KEY=new-secret-access-key

# 3. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å†èµ·å‹•
docker-compose up -d --no-deps api

# 4. æ—§Access Keyã‚’å‰Šé™¤
aws iam delete-access-key --user-name ai-interviewer-service --access-key-id OLD_KEY_ID
```

### 7.3 ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³

#### 7.3.1 Dependabotè¨­å®š

**.github/dependabot.yml:**
```yaml
version: 2
updates:
  # Pythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ (backend)
  - package-ecosystem: "pip"
    directory: "/apps/backend"
    schedule:
      interval: "weekly"
      day: "monday"
      time: "09:00"
    open-pull-requests-limit: 10
    reviewers:
      - "sre-team"
    labels:
      - "dependencies"
      - "python"
    commit-message:
      prefix: "chore(deps)"
    ignore:
      - dependency-name: "*"
        update-types: ["version-update:semver-major"]  # ãƒ¡ã‚¸ãƒ£ãƒ¼ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¢ãƒƒãƒ—ã¯æ‰‹å‹•ç¢ºèª

  # npmãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ (frontend)
  - package-ecosystem: "npm"
    directory: "/apps/web"
    schedule:
      interval: "weekly"
      day: "monday"
      time: "09:00"
    open-pull-requests-limit: 10
    reviewers:
      - "sre-team"
    labels:
      - "dependencies"
      - "javascript"
    commit-message:
      prefix: "chore(deps)"
    ignore:
      - dependency-name: "*"
        update-types: ["version-update:semver-major"]

  # GitHub Actions
  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: "monthly"
    labels:
      - "dependencies"
      - "github-actions"
```

#### 7.3.2 æ‰‹å‹•ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³

**Python (backend):**
```bash
# pip-audit ã§ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³
cd apps/backend
pip install pip-audit
pip-audit

# Safetyã§ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³
pip install safety
safety check --json

# Banditã§é™çš„è§£æ (ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§æ¤œå‡º)
pip install bandit
bandit -r grc_backend/ -f json -o security-report.json
```

**Node.js (frontend):**
```bash
# npm audit
cd apps/web
pnpm audit

# è‡ªå‹•ä¿®æ­£å¯èƒ½ãªè„†å¼±æ€§ã‚’ä¿®æ­£
pnpm audit --fix

# è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ
pnpm audit --json > security-audit.json
```

**Docker ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚¹ã‚­ãƒ£ãƒ³:**
```bash
# Trivyã§ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã‚¹ã‚­ãƒ£ãƒ³
docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
  aquasec/trivy image ai-interviewer-api:latest

# é‡å¤§åº¦HIGHä»¥ä¸Šã®ã¿è¡¨ç¤º
docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
  aquasec/trivy image --severity HIGH,CRITICAL ai-interviewer-api:latest

# JSONå½¢å¼ã§å‡ºåŠ›
docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
  aquasec/trivy image --format json --output trivy-report.json ai-interviewer-api:latest
```

### 7.4 ã‚¢ã‚¯ã‚»ã‚¹ãƒ­ã‚°ç›£æŸ»

#### 7.4.1 ã‚¢ã‚¯ã‚»ã‚¹ãƒ­ã‚°å½¢å¼

**Nginx ã‚¢ã‚¯ã‚»ã‚¹ãƒ­ã‚° (JSONå½¢å¼):**
```nginx
# /etc/nginx/nginx.conf
log_format json_combined escape=json
  '{'
    '"time_local":"$time_local",'
    '"remote_addr":"$remote_addr",'
    '"remote_user":"$remote_user",'
    '"request":"$request",'
    '"status": "$status",'
    '"body_bytes_sent":"$body_bytes_sent",'
    '"request_time":"$request_time",'
    '"http_referrer":"$http_referer",'
    '"http_user_agent":"$http_user_agent",'
    '"http_x_forwarded_for":"$http_x_forwarded_for"'
  '}';

access_log /var/log/nginx/access.log json_combined;
```

#### 7.4.2 ä¸å¯©ãªã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º

**ç›£æŸ»ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹:**
```bash
#!/bin/bash
# audit_access_logs.sh

LOG_FILE="/var/log/nginx/access.log"
SLACK_WEBHOOK="your-slack-webhook-url"

# éå»1æ™‚é–“ã®ãƒ­ã‚°ã‚’è§£æ
since_time=$(date -d '1 hour ago' '+%d/%b/%Y:%H:%M:%S')

# 1. å¤§é‡ã®4xx/5xxã‚¨ãƒ©ãƒ¼æ¤œå‡º (IPå˜ä½)
suspicious_ips=$(cat $LOG_FILE | \
  jq -r 'select(.status >= "400") | .remote_addr' | \
  sort | uniq -c | sort -rn | \
  awk '$1 > 100 {print $2}')

if [ ! -z "$suspicious_ips" ]; then
  echo "âš ï¸ Suspicious IPs with high error rate detected:"
  echo "$suspicious_ips"

  curl -X POST "$SLACK_WEBHOOK" \
    -H 'Content-Type: application/json' \
    -d "{
      \"text\": \"âš ï¸ Security Alert: Suspicious IPs detected\",
      \"blocks\": [
        {
          \"type\": \"section\",
          \"text\": {
            \"type\": \"mrkdwn\",
            \"text\": \"*IPs with >100 errors in the last hour:*\n\`\`\`$suspicious_ips\`\`\`\"
          }
        }
      ]
    }"
fi

# 2. èªè¨¼å¤±æ•—ã®å¤šã„IPæ¤œå‡º
auth_failures=$(cat $LOG_FILE | \
  jq -r 'select(.request | contains("/auth/login") and .status == "401") | .remote_addr' | \
  sort | uniq -c | sort -rn | \
  awk '$1 > 10 {print $2}')

if [ ! -z "$auth_failures" ]; then
  echo "ğŸš¨ Brute force attack detected:"
  echo "$auth_failures"

  # è©²å½“IPã‚’ãƒ–ãƒ­ãƒƒã‚¯ (fail2banç­‰ã¨é€£æº)
  for ip in $auth_failures; do
    echo "Blocking IP: $ip"
    iptables -A INPUT -s $ip -j DROP
  done
fi

# 3. SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³è©¦è¡Œæ¤œå‡º
sql_injection=$(cat $LOG_FILE | \
  jq -r 'select(.request | test("(SELECT|UNION|DROP|INSERT|UPDATE|DELETE|\\-\\-|;)"; "i")) | .remote_addr' | \
  sort | uniq)

if [ ! -z "$sql_injection" ]; then
  echo "ğŸš¨ SQL Injection attempt detected:"
  echo "$sql_injection"

  curl -X POST "$SLACK_WEBHOOK" \
    -H 'Content-Type: application/json' \
    -d "{
      \"text\": \"ğŸš¨ CRITICAL: SQL Injection attempt detected\",
      \"blocks\": [
        {
          \"type\": \"section\",
          \"text\": {
            \"type\": \"mrkdwn\",
            \"text\": \"*IPs attempting SQL injection:*\n\`\`\`$sql_injection\`\`\`\"
          }
        }
      ]
    }"
fi
```

**crontabè¨­å®š:**
```bash
# æ¯æ™‚00åˆ†ã«ã‚¢ã‚¯ã‚»ã‚¹ãƒ­ã‚°ç›£æŸ»å®Ÿè¡Œ
0 * * * * /opt/scripts/audit_access_logs.sh >> /var/log/security/audit.log 2>&1
```

---

## ä»˜éŒ²

### A. ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

**ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ãŒå¿œç­”ã—ãªã„å ´åˆ:**
```
â–¡ ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª
â–¡ APIã‚µãƒ¼ãƒãƒ¼ã®ãƒ—ãƒ­ã‚»ã‚¹ç¢ºèª (docker ps / kubectl get pods)
â–¡ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆç¢ºèª (/api/v1/health)
â–¡ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç¢ºèª
â–¡ Redisæ¥ç¶šç¢ºèª
â–¡ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šç¢ºèª
â–¡ ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³ç¢ºèª (CPU/ãƒ¡ãƒ¢ãƒª/ãƒ‡ã‚£ã‚¹ã‚¯)
â–¡ ãƒ­ã‚°ç¢ºèª (ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç‰¹å®š)
```

**ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä½ä¸‹ã®å ´åˆ:**
```
â–¡ APIå¿œç­”æ™‚é–“ã®ç¢ºèª (P50/P95/P99)
â–¡ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªæ™‚é–“ã®ç¢ºèª
â–¡ ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªãƒ­ã‚°ã®ç¢ºèª
â–¡ Redis ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ã®ç¢ºèª
â–¡ AI Providerå¿œç­”æ™‚é–“ã®ç¢ºèª
â–¡ ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨ç‡ã®ç¢ºèª (CPU/ãƒ¡ãƒ¢ãƒª)
â–¡ åŒæ™‚æ¥ç¶šæ•°ã®ç¢ºèª
â–¡ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¸¯åŸŸã®ç¢ºèª
```

### B. é€£çµ¡å…ˆãƒ»å‚è€ƒãƒªã‚½ãƒ¼ã‚¹

**ç¤¾å†…é€£çµ¡å…ˆ:**
| æ‹…å½“ | Email | é›»è©± | å¯¾å¿œæ™‚é–“ |
|------|-------|------|---------|
| SREãƒãƒ¼ãƒ  | sre@example.com | xxx-xxxx-xxxx | 24/7 |
| é–‹ç™ºãƒãƒ¼ãƒ  | dev@example.com | xxx-xxxx-xxxx | å¹³æ—¥9-18æ™‚ |
| ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒãƒ¼ãƒ  | security@example.com | xxx-xxxx-xxxx | å¹³æ—¥9-18æ™‚ |

**å¤–éƒ¨ã‚µãƒãƒ¼ãƒˆ:**
| ã‚µãƒ¼ãƒ“ã‚¹ | ã‚µãƒãƒ¼ãƒˆçª“å£ | SLA |
|---------|------------|-----|
| Azure OpenAI | https://azure.microsoft.com/support/ | Business: 1æ™‚é–“ä»¥å†… |
| AWS | https://aws.amazon.com/premiumsupport/ | Business: 1æ™‚é–“ä»¥å†… |
| PostgreSQL | https://www.postgresql.org/support/ | ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ |

**ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:**
- ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£: `/docs/architecture/ARCHITECTURE.md`
- APIä»•æ§˜: `/docs/api/API_SPECIFICATION.md`
- é–‹ç™ºè€…ã‚¬ã‚¤ãƒ‰: `/docs/development/DEVELOPER_GUIDE.md`

---

**END OF OPERATION MANUAL**
