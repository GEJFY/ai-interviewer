# リソース見積もりガイド

AI Interview System の本番環境デプロイメントに必要なインフラリソースとコストの見積もりガイドです。

## システムアーキテクチャ概要

本システムは以下のコンポーネントで構成されています。

- **Backend API**: FastAPI (Python)、ステートレス、水平スケーラブル
- **Frontend**: Next.js 15 SSR/SSG
- **PostgreSQL**: プライマリデータベース
- **Redis**: キャッシュ + セッション管理 + ジョブキュー
- **AI APIs**: Azure OpenAI / AWS Bedrock / GCP Vertex AI (従量課金)
- **WebSocket**: リアルタイムインタビュー接続

## 1. デプロイメント規模別スペック

### Small（小規模）

**想定規模**
- ユーザー数: 〜50人
- インタビュー実施数: 〜100件/月
- 同時接続数: 〜5セッション

**推奨スペック**

| コンポーネント | スペック |
|--------------|---------|
| Backend API | 1インスタンス × (2vCPU / 4GB RAM) |
| Frontend Web | 1インスタンス × (1vCPU / 2GB RAM) |
| PostgreSQL | 2vCPU / 8GB RAM / 50GB SSD |
| Redis | 1vCPU / 2GB RAM |

**特徴**
- シングルインスタンス構成で運用可能
- 基本的な冗長性なし（コスト重視）
- 開発環境やPoCに最適

---

### Medium（中規模）

**想定規模**
- ユーザー数: 〜200人
- インタビュー実施数: 〜500件/月
- 同時接続数: 〜20セッション

**推奨スペック**

| コンポーネント | スペック |
|--------------|---------|
| Backend API | 2インスタンス × (2vCPU / 4GB RAM) |
| Frontend Web | 2インスタンス × (1vCPU / 2GB RAM) |
| PostgreSQL | 4vCPU / 16GB RAM / 100GB SSD |
| Redis | 2vCPU / 4GB RAM |

**特徴**
- ロードバランサー配下での冗長構成
- 基本的なHA（高可用性）対応
- 一般的な企業利用に最適

---

### Large（大規模）

**想定規模**
- ユーザー数: 〜1,000人
- インタビュー実施数: 〜2,000件/月
- 同時接続数: 〜50セッション

**推奨スペック**

| コンポーネント | スペック |
|--------------|---------|
| Backend API | 4インスタンス × (4vCPU / 8GB RAM) |
| Frontend Web | 3インスタンス × (2vCPU / 4GB RAM) |
| PostgreSQL | 8vCPU / 32GB RAM / 500GB SSD + Read Replica |
| Redis | 4vCPU / 8GB RAM (Cluster構成) |

**特徴**
- マルチAZ構成での高可用性
- DB Read Replicaによる読み取り負荷分散
- Redis Clusterによるキャッシュ分散
- エンタープライズ利用に最適

---

## 2. クラウドプロバイダー別月額概算

### Azure

**サービス構成**
- Compute: Azure App Service / Azure Kubernetes Service (AKS)
- Database: Azure Database for PostgreSQL - Flexible Server
- Cache: Azure Cache for Redis
- Network: Azure Load Balancer + Azure Front Door

| 規模 | API + Web | PostgreSQL | Redis | その他 | **合計(USD/月)** |
|-----|-----------|-----------|-------|--------|----------------|
| Small | $150 | $120 | $50 | $30 | **$350** |
| Medium | $400 | $350 | $120 | $80 | **$950** |
| Large | $1,200 | $900 | $300 | $200 | **$2,600** |

---

### AWS

**サービス構成**
- Compute: Amazon ECS / Amazon EKS
- Database: Amazon RDS for PostgreSQL
- Cache: Amazon ElastiCache for Redis
- Network: Application Load Balancer + CloudFront

| 規模 | API + Web | RDS PostgreSQL | ElastiCache | その他 | **合計(USD/月)** |
|-----|-----------|---------------|-------------|--------|----------------|
| Small | $140 | $110 | $45 | $35 | **$330** |
| Medium | $380 | $320 | $110 | $90 | **$900** |
| Large | $1,150 | $850 | $280 | $220 | **$2,500** |

---

### GCP

**サービス構成**
- Compute: Cloud Run / Google Kubernetes Engine (GKE)
- Database: Cloud SQL for PostgreSQL
- Cache: Memorystore for Redis
- Network: Cloud Load Balancing + Cloud CDN

| 規模 | API + Web | Cloud SQL | Memorystore | その他 | **合計(USD/月)** |
|-----|-----------|-----------|-------------|--------|----------------|
| Small | $135 | $115 | $48 | $32 | **$330** |
| Medium | $370 | $330 | $115 | $85 | **$900** |
| Large | $1,100 | $880 | $290 | $210 | **$2,480** |

**注意事項**
- 上記金額は概算であり、実際の利用状況により変動します
- データ転送料金、バックアップストレージは別途発生します
- リザーブドインスタンス利用で最大40%のコスト削減が可能です

---

## 3. AI APIコスト見積もり

### インタビュー1回あたりのトークン使用量

**会話ターン（平均15ターン）**
- Input tokens: 約2,000 tokens/ターン
- Output tokens: 約1,500 tokens/ターン
- 合計: (2,000 + 1,500) × 15 = **52,500 tokens/インタビュー**

**レポート生成1件**
- Input tokens: 約5,000 tokens（インタビュー全文）
- Output tokens: 約3,000 tokens（レポート生成）
- 合計: **8,000 tokens/レポート**

**セマンティック検索**
- Embedding tokens: 約500 tokens/クエリ
- 月間平均クエリ数: インタビュー数 × 2回（候補者検索+類似インタビュー検索）

### 料金体系（GPT-4o-mini基準）

| トークンタイプ | 料金 |
|--------------|------|
| Input tokens | $0.15 / 1M tokens |
| Output tokens | $0.60 / 1M tokens |
| Embedding tokens | $0.02 / 1M tokens |

### 月額AI APIコスト概算

#### Small規模（100インタビュー/月）

```
インタビュー会話:
  Input:  100 × 2,000 × 15 × $0.15 / 1M = $4.50
  Output: 100 × 1,500 × 15 × $0.60 / 1M = $13.50

レポート生成:
  Input:  100 × 5,000 × $0.15 / 1M = $0.75
  Output: 100 × 3,000 × $0.60 / 1M = $1.80

セマンティック検索:
  Embedding: 200 × 500 × $0.02 / 1M = $0.02

合計: 約 $20.57/月
```

#### Medium規模（500インタビュー/月）

```
インタビュー会話:
  Input:  500 × 2,000 × 15 × $0.15 / 1M = $22.50
  Output: 500 × 1,500 × 15 × $0.60 / 1M = $67.50

レポート生成:
  Input:  500 × 5,000 × $0.15 / 1M = $3.75
  Output: 500 × 3,000 × $0.60 / 1M = $9.00

セマンティック検索:
  Embedding: 1,000 × 500 × $0.02 / 1M = $0.10

合計: 約 $102.85/月
```

#### Large規模（2,000インタビュー/月）

```
インタビュー会話:
  Input:  2,000 × 2,000 × 15 × $0.15 / 1M = $90.00
  Output: 2,000 × 1,500 × 15 × $0.60 / 1M = $270.00

レポート生成:
  Input:  2,000 × 5,000 × $0.15 / 1M = $15.00
  Output: 2,000 × 3,000 × $0.60 / 1M = $36.00

セマンティック検索:
  Embedding: 4,000 × 500 × $0.02 / 1M = $0.40

合計: 約 $411.40/月
```

### AI APIモデル別比較

| モデル | 相対コスト | 特徴 |
|-------|-----------|------|
| GPT-4o-mini | 1x (基準) | コストパフォーマンス最適 |
| GPT-4o | 約10x | 高度な推論能力、複雑な質問生成 |
| Claude 3.5 Sonnet | 約3x | 長文理解に優れる、詳細なレポート生成 |
| Gemini 1.5 Flash | 約0.7x | 最もコストが低い、基本的な会話 |

---

## 4. ストレージ見積もり

### データベース容量

**インタビューデータ**
- 1インタビューあたり: 約1MB
  - 会話ログ: 0.6MB（JSON形式）
  - メタデータ: 0.1MB（候補者情報、評価スコア等）
  - ベクトル埋め込み: 0.3MB（セマンティック検索用）

**レポートデータ**
- 1レポートあたり: 約0.5MB
  - テキストレポート: 0.3MB（Markdown/HTML）
  - 分析データ: 0.2MB（統計情報、グラフデータ）

**ユーザーデータ**
- 1ユーザーあたり: 約50KB
  - プロフィール情報、権限設定等

### 規模別ストレージ必要量

| 規模 | インタビュー | レポート | ユーザー | バックアップ | **合計** |
|-----|------------|---------|---------|------------|---------|
| Small (年間1,200件) | 1.2GB | 0.6GB | 2.5MB | 2GB | **4GB** |
| Medium (年間6,000件) | 6GB | 3GB | 10MB | 10GB | **19GB** |
| Large (年間24,000件) | 24GB | 12GB | 50MB | 40GB | **76GB** |

**推奨プロビジョニング容量**
- Small: 50GB（約12倍の余裕）
- Medium: 100GB（約5倍の余裕）
- Large: 500GB（約6.5倍の余裕）

### Redisメモリ使用量

**セッションデータ**
- 1セッションあたり: 約10KB
  - ユーザーセッション: 5KB
  - WebSocket接続状態: 3KB
  - 一時キャッシュ: 2KB

**同時接続数別必要メモリ**

| 規模 | 同時セッション | セッションメモリ | キャッシュ | **合計** |
|-----|--------------|----------------|-----------|---------|
| Small | 5 | 50KB | 500MB | **500MB** |
| Medium | 20 | 200KB | 1.5GB | **1.5GB** |
| Large | 50 | 500KB | 3.5GB | **3.5GB** |

---

## 5. ネットワーク帯域

### WebSocket通信

**テキストベース会話モード**
- 送信（クライアント→サーバー）: 約2KB/メッセージ
- 受信（サーバー→クライアント）: 約3KB/メッセージ
- 平均頻度: 1メッセージ/30秒
- 実効帯域: **約5KB/s per active session**

**音声ストリーミングモード**
- 音声データ: 16kbps (16KB/s)
- テキスト同時送信: 1KB/s
- 実効帯域: **約17KB/s per active session**

### 規模別ネットワーク帯域要件

#### Small規模（同時5セッション）

| 通信タイプ | 帯域 |
|-----------|------|
| WebSocket (テキスト) | 25KB/s = 0.2Mbps |
| WebSocket (音声) | 85KB/s = 0.68Mbps |
| HTTP API | 100KB/s = 0.8Mbps |
| **合計ピーク時** | **約2Mbps** |

#### Medium規模（同時20セッション）

| 通信タイプ | 帯域 |
|-----------|------|
| WebSocket (テキスト) | 100KB/s = 0.8Mbps |
| WebSocket (音声) | 340KB/s = 2.72Mbps |
| HTTP API | 400KB/s = 3.2Mbps |
| **合計ピーク時** | **約7Mbps** |

#### Large規模（同時50セッション）

| 通信タイプ | 帯域 |
|-----------|------|
| WebSocket (テキスト) | 250KB/s = 2Mbps |
| WebSocket (音声) | 850KB/s = 6.8Mbps |
| HTTP API | 1MB/s = 8Mbps |
| **合計ピーク時** | **約17Mbps** |

### データ転送量（月間）

**インタビュー1回あたりのデータ転送量**
- テキストモード: 約2MB（30分セッション想定）
- 音声モード: 約30MB（30分セッション想定）

**月間データ転送量概算**

| 規模 | インタビュー数 | テキストモード | 音声モード | **合計（混在）** |
|-----|--------------|--------------|-----------|----------------|
| Small | 100件/月 | 200MB | 3GB | **約1.6GB** |
| Medium | 500件/月 | 1GB | 15GB | **約8GB** |
| Large | 2,000件/月 | 4GB | 60GB | **約32GB** |

※ 音声モード使用率を50%と仮定

---

## 総合コスト概算サマリー

### Small規模（〜50ユーザー、〜100インタビュー/月）

| カテゴリ | Azure | AWS | GCP |
|---------|-------|-----|-----|
| インフラ | $350 | $330 | $330 |
| AI API | $21 | $21 | $21 |
| **月額合計** | **$371** | **$351** | **$351** |

---

### Medium規模（〜200ユーザー、〜500インタビュー/月）

| カテゴリ | Azure | AWS | GCP |
|---------|-------|-----|-----|
| インフラ | $950 | $900 | $900 |
| AI API | $103 | $103 | $103 |
| **月額合計** | **$1,053** | **$1,003** | **$1,003** |

---

### Large規模（〜1,000ユーザー、〜2,000インタビュー/月）

| カテゴリ | Azure | AWS | GCP |
|---------|-------|-----|-----|
| インフラ | $2,600 | $2,500 | $2,480 |
| AI API | $411 | $411 | $411 |
| **月額合計** | **$3,011** | **$2,911** | **$2,891** |

---

## コスト最適化のヒント

### インフラ最適化

1. **リザーブドインスタンス/Savings Plans**
   - 1年コミットメントで最大30-40%削減
   - 本番環境の定常リソースに適用

2. **オートスケーリング**
   - 業務時間外のリソース削減
   - 平均30%のコスト削減が可能

3. **スポットインスタンス（開発環境）**
   - 開発/テスト環境で最大70%削減

### AI APIコスト最適化

1. **モデル選択**
   - 標準的な会話: GPT-4o-mini / Gemini Flash（低コスト）
   - 複雑な技術面接: GPT-4o / Claude 3.5（高品質）

2. **プロンプトキャッシング**
   - 会話コンテキストの再利用で最大50%削減
   - Azure OpenAI, Claude APIで利用可能

3. **バッチ処理**
   - レポート生成の非同期バッチ処理で最大50%削減

### ストレージ最適化

1. **データアーカイブ**
   - 90日以上前のインタビューをコールドストレージへ
   - 最大80%のストレージコスト削減

2. **データ圧縮**
   - 会話ログのGzip圧縮で約70%削減

---

## まとめ

本ガイドの見積もりは標準的な利用パターンを想定しています。実際のコストは以下の要因により変動します。

- AI APIの利用頻度とモデル選択
- 音声モードの利用率
- データ保持期間とバックアップポリシー
- 地理的分散とマルチリージョン構成

本番環境構築前に、パイロット運用による実績データの収集を推奨します。
