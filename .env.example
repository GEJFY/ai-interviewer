# =============================================================================
# AI Interview Tool - 環境変数設定
# =============================================================================
# このファイルを .env にコピーして使用してください
# cp .env.example .env
# =============================================================================
#
# ★ クイックスタート（ローカル開発の最小設定）
# -------------------------------------------
# クラウドAPIキーが無くても、Ollama（ローカルLLM）で開発を始められます。
# 以下の3項目だけ設定すれば、他はデフォルト値で動作します:
#
#   AI_PROVIDER=local
#   OLLAMA_BASE_URL=http://localhost:11434
#   OLLAMA_MODEL=gemma3:1b
#
# Ollamaのインストール: https://ollama.com/
# モデルのダウンロード: ollama pull gemma3:1b
# =============================================================================

# =============================================================================
# 基本設定
# =============================================================================

# 環境 (development | staging | production)
ENVIRONMENT=development

# シークレットキー（本番では必ず変更してください！）
# 生成方法: python -c "import secrets; print(secrets.token_urlsafe(64))"
SECRET_KEY=your-secret-key-change-in-production

# デバッグモード（本番では false）
DEBUG=true

# デモデータ自動投入（Docker起動時にデモデータを自動投入）
# true にすると起動時にデモデータがDBに投入されます
SEED_DEMO=false

# ログ設定
LOG_LEVEL=DEBUG
JSON_LOGS=false

# =============================================================================
# ポート設定（Docker使用時）
# =============================================================================
# Docker環境でのホストポートマッピング
# 直接起動でも同じポートを使用（他アプリとの競合回避）
BACKEND_PORT=8100
WEB_PORT=3100

# =============================================================================
# データベース設定
# =============================================================================

POSTGRES_USER=grc_user
POSTGRES_PASSWORD=grc_password
POSTGRES_DB=ai_interviewer
POSTGRES_PORT=5434
DATABASE_URL=postgresql+asyncpg://grc_user:grc_password@localhost:5434/ai_interviewer

# 接続プール設定（本番ではワーカー数に合わせて調整）
# pool_size × workers = 最大同時接続数 (例: 10 × 4 = 40)
DB_POOL_SIZE=10
DB_MAX_OVERFLOW=20

# =============================================================================
# Redis設定
# =============================================================================

REDIS_PORT=6380
REDIS_URL=redis://localhost:6380/0

# =============================================================================
# セキュリティ設定
# =============================================================================

# JWT設定
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
REFRESH_TOKEN_EXPIRE_DAYS=7

# CORS設定（カンマ区切りで複数指定可）
CORS_ORIGINS=http://localhost:3100,http://127.0.0.1:3100

# レート制限
RATE_LIMIT_ENABLED=false
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=60

# =============================================================================
# AIプロバイダー設定 (2026年最新モデル対応)
# =============================================================================
# 選択: azure | aws | gcp | local
AI_PROVIDER=azure

# -----------------------------------------------------------------------------
# Microsoft Foundry (旧 Azure AI Foundry / Azure OpenAI)
# -----------------------------------------------------------------------------
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_KEY=your-api-key
AZURE_OPENAI_API_VERSION=2024-12-01

# デプロイ済みモデル名
AZURE_OPENAI_DEPLOYMENT_GPT52=gpt-5.2
AZURE_OPENAI_DEPLOYMENT_GPT5_NANO=gpt-5-nano
AZURE_OPENAI_DEPLOYMENT_CLAUDE=claude-sonnet-4.6-opus
AZURE_OPENAI_DEPLOYMENT_EMBEDDING=text-embedding-3-large

# -----------------------------------------------------------------------------
# OpenAI Direct
# -----------------------------------------------------------------------------
OPENAI_API_KEY=
OPENAI_ORG_ID=

# -----------------------------------------------------------------------------
# Anthropic Direct
# -----------------------------------------------------------------------------
ANTHROPIC_API_KEY=

# -----------------------------------------------------------------------------
# AWS Bedrock
# -----------------------------------------------------------------------------
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_REGION=ap-northeast-1

# Bedrock モデルID
AWS_BEDROCK_MODEL_CLAUDE_OPUS=anthropic.claude-sonnet-4.6-opus-v1:0
AWS_BEDROCK_MODEL_CLAUDE_HAIKU=anthropic.claude-4.6-haiku-v1:0
AWS_BEDROCK_MODEL_NOVA_LITE=amazon.nova-lite-v1:0

# -----------------------------------------------------------------------------
# GCP Vertex AI
# -----------------------------------------------------------------------------
GCP_PROJECT_ID=
GCP_LOCATION=asia-northeast1
GOOGLE_APPLICATION_CREDENTIALS=./credentials/gcp-credentials.json

# Vertex AI モデルID
GCP_VERTEX_MODEL_GEMINI_PRO=gemini-3.0-pro-preview
GCP_VERTEX_MODEL_GEMINI_FLASH=gemini-3.0-flash-preview

# -----------------------------------------------------------------------------
# Ollama (Local LLM) - 開発・テスト環境向け
# -----------------------------------------------------------------------------
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=gemma3:1b
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# =============================================================================
# 音声サービス設定
# =============================================================================
# 選択: azure | aws | gcp
SPEECH_PROVIDER=azure

# -----------------------------------------------------------------------------
# Azure Speech Services
# -----------------------------------------------------------------------------
AZURE_SPEECH_KEY=your-speech-key
AZURE_SPEECH_REGION=japaneast

# 音声設定
AZURE_SPEECH_VOICE_JA=ja-JP-NanamiNeural
AZURE_SPEECH_VOICE_EN=en-US-JennyNeural

# -----------------------------------------------------------------------------
# AWS Transcribe/Polly
# -----------------------------------------------------------------------------
# AWS認証情報はBedrock設定と共有

# -----------------------------------------------------------------------------
# GCP Speech-to-Text / Text-to-Speech
# -----------------------------------------------------------------------------
# GCP認証情報はVertex AI設定と共有

# =============================================================================
# ストレージ設定
# =============================================================================
# 選択: azure | aws | gcp | local
STORAGE_PROVIDER=local

# Azure Blob Storage
AZURE_STORAGE_CONNECTION_STRING=
AZURE_STORAGE_CONTAINER_AUDIO=audio-files
AZURE_STORAGE_CONTAINER_REPORTS=reports

# AWS S3
AWS_S3_BUCKET_NAME=ai-interviewer

# GCP Cloud Storage
GCP_STORAGE_BUCKET_NAME=ai-interviewer

# ローカルストレージ（開発用）
LOCAL_STORAGE_PATH=./storage

# =============================================================================
# フロントエンド設定
# =============================================================================

NEXT_PUBLIC_API_URL=http://localhost:8100
NEXT_PUBLIC_WS_URL=ws://localhost:8100
NEXT_PUBLIC_ENVIRONMENT=development

# Azure AD SSO（設定するとログイン画面に「Azure AD でログイン」ボタンが表示されます）
NEXT_PUBLIC_AZURE_AD_CLIENT_ID=
NEXT_PUBLIC_AZURE_AD_TENANT_ID=

# =============================================================================
# 監視・トレーシング設定（オプション）
# =============================================================================

# OpenTelemetry
OTEL_ENABLED=false
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
OTEL_SERVICE_NAME=ai-interviewer

# Application Insights (Azure)
APPLICATIONINSIGHTS_CONNECTION_STRING=

# =============================================================================
# SSO設定（オプション）
# =============================================================================

# Azure AD
AZURE_AD_CLIENT_ID=
AZURE_AD_CLIENT_SECRET=
AZURE_AD_TENANT_ID=

# Okta
OKTA_DOMAIN=
OKTA_CLIENT_ID=
OKTA_CLIENT_SECRET=
